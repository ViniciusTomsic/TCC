{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b382871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl.metadata (11 kB)\n",
      "Requirement already satisfied: xgboost in c:\\users\\vinic\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (3.1.1)\n",
      "Requirement already satisfied: numpy>=1.22.0 in c:\\users\\vinic\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (2.3.2)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\vinic\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from scikit-learn) (1.16.2)\n",
      "Collecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.5.2-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.7.2-cp311-cp311-win_amd64.whl (8.9 MB)\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/8.9 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/8.9 MB 1.1 MB/s eta 0:00:08\n",
      "    --------------------------------------- 0.2/8.9 MB 1.8 MB/s eta 0:00:05\n",
      "   - -------------------------------------- 0.3/8.9 MB 2.1 MB/s eta 0:00:05\n",
      "   -- ------------------------------------- 0.6/8.9 MB 2.7 MB/s eta 0:00:04\n",
      "   -- ------------------------------------- 0.6/8.9 MB 2.5 MB/s eta 0:00:04\n",
      "   --- ------------------------------------ 0.8/8.9 MB 2.7 MB/s eta 0:00:04\n",
      "   ---- ----------------------------------- 0.9/8.9 MB 2.7 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 1.2/8.9 MB 2.9 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 1.4/8.9 MB 3.0 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 1.6/8.9 MB 3.2 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 1.9/8.9 MB 3.5 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 2.2/8.9 MB 3.7 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 2.5/8.9 MB 3.9 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.7/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ------------ --------------------------- 2.9/8.9 MB 4.0 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 3.2/8.9 MB 4.1 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 4.0/8.9 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------- ------------------- 4.6/8.9 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------- ----------------- 5.0/8.9 MB 5.5 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 5.4/8.9 MB 5.7 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 6.1/8.9 MB 6.0 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 6.8/8.9 MB 6.5 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 7.7/8.9 MB 7.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 8.2/8.9 MB 7.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  8.9/8.9 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 8.9/8.9 MB 7.4 MB/s eta 0:00:00\n",
      "Downloading joblib-1.5.2-py3-none-any.whl (308 kB)\n",
      "   ---------------------------------------- 0.0/308.4 kB ? eta -:--:--\n",
      "   ---------------------------------------- 308.4/308.4 kB 9.6 MB/s eta 0:00:00\n",
      "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, joblib, scikit-learn\n",
      "Successfully installed joblib-1.5.2 scikit-learn-1.7.2 threadpoolctl-3.6.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\vinic\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn xgboost\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "acfc1f13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos CSV carregados com sucesso!\n",
      "\n",
      "========================================\n",
      "  CONTAGEM DE AMOSTRAS - CONJUNTO DE TREINO\n",
      "========================================\n",
      "tipo_falha_adicionada\n",
      "Esfera           5640\n",
      "Normal            470\n",
      "Pista Externa    5640\n",
      "Pista Interna    5640\n",
      "Name: count, dtype: int64\n",
      "\n",
      "========================================\n",
      "  CONTAGEM DE AMOSTRAS - CONJUNTO de TESTE\n",
      "========================================\n",
      "tipo_falha_adicionada\n",
      "Esfera            997\n",
      "Normal            115\n",
      "Pista Externa     750\n",
      "Pista Interna    1035\n",
      "Name: count, dtype: int64\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 6: VERIFICAÇÃO E PLOTAGEM DA DISTRIBUIÇÃO DAS CLASSES\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "\n",
    "# --- 1. CARREGAR OS DADOS ---\n",
    "\n",
    "# Caminho onde os CSVs foram salvos (ajuste se for diferente)\n",
    "caminho_base_output = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC'\n",
    "caminho_csv_treino = os.path.join(caminho_base_output, 'df_treino_features.csv')\n",
    "caminho_csv_teste = os.path.join(caminho_base_output, 'df_teste_features.csv')\n",
    "\n",
    "try:\n",
    "    df_treino = pd.read_csv(caminho_csv_treino)\n",
    "    df_teste = pd.read_csv(caminho_csv_teste)\n",
    "    print(\"Arquivos CSV carregados com sucesso!\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivos CSV não encontrados no caminho: {caminho_base_output}\")\n",
    "    print(\"Verifique se o Bloco 4 foi executado e os arquivos estão no local correto.\")\n",
    "    # Se der erro aqui, não continue o script\n",
    "    raise\n",
    "\n",
    "# Coluna alvo\n",
    "target_column = 'tipo_falha_adicionada'\n",
    "\n",
    "# --- 2. CONTAR AMOSTRAS (TEXTO) ---\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"  CONTAGEM DE AMOSTRAS - CONJUNTO DE TREINO\")\n",
    "print(\"=\"*40)\n",
    "counts_treino = df_treino[target_column].value_counts().sort_index()\n",
    "print(counts_treino)\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"  CONTAGEM DE AMOSTRAS - CONJUNTO de TESTE\")\n",
    "print(\"=\"*40)\n",
    "counts_teste = df_teste[target_column].value_counts().sort_index()\n",
    "print(counts_teste)\n",
    "print(\"\\n\")\n",
    "\n",
    "\n",
    "# Lista das estatísticas que queremos ver\n",
    "stats_para_mostrar = ['mean', 'std', 'min', 'max']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5246dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivos CSV carregados com sucesso!\n",
      "Amostras de Treino: 17390, Amostras de Teste: 2897\n",
      "\n",
      "Classes (alvo) codificadas: ['Esfera', 'Normal', 'Pista Externa', 'Pista Interna']\n",
      "\n",
      "Pré-processamento concluído: LabelEncoder e StandardScaler aplicados.\n",
      "\n",
      "--- INICIANDO TREINAMENTO DOS MODELOS ---\n",
      "Treinando QDA...\n",
      "Treinando SVM...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vinic\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 0 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinic\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 1 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinic\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 2 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n",
      "C:\\Users\\vinic\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\sklearn\\discriminant_analysis.py:1024: LinAlgWarning: The covariance matrix of class 3 is not full rank. Increasing the value of parameter `reg_param` might help reducing the collinearity.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 5: TREINAMENTO E AVALIAÇÃO DOS MODELOS (QDA, SVM, XGBOOST)\n",
    "# =============================================================================\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# --- 1. CARREGAR OS DADOS ---\n",
    "\n",
    "# Caminho onde os CSVs foram salvos (ajuste se for diferente)\n",
    "caminho_base_output = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC'\n",
    "caminho_csv_treino = os.path.join(caminho_base_output, 'df_treino_features.csv')\n",
    "caminho_csv_teste = os.path.join(caminho_base_output, 'df_teste_features.csv')\n",
    "\n",
    "try:\n",
    "    df_treino = pd.read_csv(caminho_csv_treino)\n",
    "    df_teste = pd.read_csv(caminho_csv_teste)\n",
    "    print(\"Arquivos CSV carregados com sucesso!\")\n",
    "    print(f\"Amostras de Treino: {len(df_treino)}, Amostras de Teste: {len(df_teste)}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERRO: Arquivos CSV não encontrados no caminho: {caminho_base_output}\")\n",
    "    print(\"Verifique se o Bloco 4 foi executado e os arquivos estão no local correto.\")\n",
    "    # Se der erro aqui, não continue o script\n",
    "    raise\n",
    "\n",
    "# --- 2. PREPARAÇÃO DOS DADOS (PRÉ-PROCESSAMENTO) ---\n",
    "\n",
    "# Definir colunas de features e a coluna alvo\n",
    "# (Baseado na saída do Bloco 3)\n",
    "feature_columns = [\n",
    "    'TF2_std', 'TF3_rms', 'TF4_fator_forma',\n",
    "    'FF2_freq_central', 'FF3_rms_freq', 'FF5_assimetria_espectral',\n",
    "    'FF_pico_50_200Hz'\n",
    "]\n",
    "target_column = 'tipo_falha_adicionada'\n",
    "\n",
    "# Separar X (features) e y (alvo)\n",
    "X_treino = df_treino[feature_columns]\n",
    "y_treino = df_treino[target_column]\n",
    "\n",
    "X_teste = df_teste[feature_columns]\n",
    "y_teste = df_teste[target_column]\n",
    "\n",
    "# --- 2a. Label Encoding (para a variável alvo 'y') ---\n",
    "# Modelos precisam de alvos numéricos (ex: 0, 1, 2) em vez de ('Normal', 'Esfera', ...)\n",
    "le = LabelEncoder()\n",
    "y_treino_encoded = le.fit_transform(y_treino)\n",
    "y_teste_encoded = le.transform(y_teste) # Usa o 'transform' para garantir a mesma ordem\n",
    "\n",
    "# Salvar os nomes das classes para os relatórios\n",
    "class_names = le.classes_\n",
    "print(f\"\\nClasses (alvo) codificadas: {list(class_names)}\")\n",
    "\n",
    "# --- 2b. Feature Scaling (para as features 'X') ---\n",
    "# (Importante para SVM e QDA)\n",
    "scaler = StandardScaler()\n",
    "X_treino_scaled = scaler.fit_transform(X_treino)\n",
    "X_teste_scaled = scaler.transform(X_teste) # Apenas 'transform' no teste (evita data leakage)\n",
    "\n",
    "print(\"\\nPré-processamento concluído: LabelEncoder e StandardScaler aplicados.\")\n",
    "\n",
    "# --- 3. DEFINIÇÃO E TREINAMENTO DOS MODELOS ---\n",
    "\n",
    "# Dicionário com os modelos a serem treinados\n",
    "models = {\n",
    "    'QDA': QuadraticDiscriminantAnalysis(),\n",
    "    'SVM': SVC(kernel='rbf', probability=True, random_state=42),\n",
    "    'XGBoost': XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', random_state=42)\n",
    "}\n",
    "\n",
    "# Dicionário para armazenar os modelos treinados\n",
    "trained_models = {}\n",
    "\n",
    "print(\"\\n--- INICIANDO TREINAMENTO DOS MODELOS ---\")\n",
    "for name, model in models.items():\n",
    "    print(f\"Treinando {name}...\")\n",
    "    model.fit(X_treino_scaled, y_treino_encoded)\n",
    "    trained_models[name] = model\n",
    "print(\"--- TREINAMENTO CONCLUÍDO ---\")\n",
    "\n",
    "# --- 4. AVALIAÇÃO DOS MODELOS NO CONJUNTO DE TESTE ---\n",
    "\n",
    "print(\"\\n--- AVALIAÇÃO DOS MODELOS NO CONJUNTO DE TESTE ---\")\n",
    "\n",
    "for name, model in trained_models.items():\n",
    "    # Fazer predições no conjunto de teste\n",
    "    y_pred = model.predict(X_teste_scaled)\n",
    "    \n",
    "    # Calcular Acurácia\n",
    "    accuracy = accuracy_score(y_teste_encoded, y_pred)\n",
    "    \n",
    "    print(f\"\\n=======================================================\")\n",
    "    print(f\"  Resultados para o modelo: {name}\")\n",
    "    print(f\"=======================================================\")\n",
    "    print(f\"Acurácia: {accuracy:.4f} (ou {accuracy*100:.2f}%)\")\n",
    "    \n",
    "    # Exibir Relatório de Classificação\n",
    "    print(\"\\nRelatório de Classificação:\")\n",
    "    print(classification_report(y_teste_encoded, y_pred, target_names=class_names, zero_division=0))\n",
    "    \n",
    "    # Exibir Matriz de Confusão\n",
    "    print(\"Matriz de Confusão:\")\n",
    "    cm = confusion_matrix(y_teste_encoded, y_pred)\n",
    "    \n",
    "    # Plotar a Matriz de Confusão\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names,\n",
    "                annot_kws={\"size\": 12}) # Aumenta o tamanho da fonte\n",
    "    plt.xlabel('Classe Predita', fontsize=12)\n",
    "    plt.ylabel('Classe Verdadeira', fontsize=12)\n",
    "    plt.title(f'Matriz de Confusão - {name}', fontsize=14)\n",
    "    plt.show()\n",
    "\n",
    "    # =================================================================\n",
    "    # VERIFICAÇÃO: Testando a performance no PRÓPRIO CONJUNTO DE TREINO\n",
    "    # =================================================================\n",
    "    print(f\"\\n--- Verificando Acurácia no TREINO para {name} ---\")\n",
    "    y_pred_treino = model.predict(X_treino_scaled)\n",
    "    accuracy_treino = accuracy_score(y_treino_encoded, y_pred_treino)\n",
    "    print(f\"Acurácia no TREINO: {accuracy_treino*100:.2f}%\")\n",
    "    \n",
    "    if accuracy_treino > 0.95:\n",
    "        print(\"-> Modelo aprendeu os dados sintéticos (Isso é o esperado)\")\n",
    "    else:\n",
    "        print(\"-> Modelo NEM SEQUER aprendeu os dados sintéticos (Problema maior)\")\n",
    "    # ================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b458e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
