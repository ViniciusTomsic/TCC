{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94f3a95d",
   "metadata": {},
   "source": [
    "## Importação dos arquivos e geração dos segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd568514",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 1: CONFIGURAÇÃO, CARREGAMENTO, DIVISÃO (80/20) E SEGMENTAÇÃO (CORRIGIDO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES GERAIS ---\n",
    "caminho_raiz = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset' # IMPORTANTE: Verifique se este caminho está correto\n",
    "params_drive_end = {'n': 9, 'd': 0.3126, 'D': 1.537, 'phi_graus': 0.0}\n",
    "TAXA_AMOSTRAL = 12000\n",
    "\n",
    "# Dicionários de mapeamento\n",
    "mapa_tipo_falha = {'IR': 'Pista Interna', 'B': 'Esfera', 'OR': 'Pista Externa', 'Normal': 'Normal'}\n",
    "mapa_diametro_falha = {'7': '0.007\"', '14': '0.014\"', '21': '0.021\"'}\n",
    "\n",
    "# --- PARÂMETROS DE SEGMENTAÇÃO ---\n",
    "tamanho_segmento = 4096\n",
    "sobreposicao_percentual = 0.3\n",
    "passo = int(tamanho_segmento * (1 - sobreposicao_percentual))\n",
    "\n",
    "# --- 2. CARREGAMENTO, DIVISÃO E PROCESSAMENTO ---\n",
    "dicionario_treino = {} # Dicionário para 80% dos dados normais\n",
    "dicionario_teste = {} # Dicionário para 20% normais + 100% falhas reais\n",
    "\n",
    "print(f\"Iniciando a leitura e segmentação dos arquivos em '{caminho_raiz}'...\")\n",
    "print(\"Dados normais serão divididos (80% treino / 20% teste).\")\n",
    "print(\"Dados de falha real irão 100% para o teste.\")\n",
    "\n",
    "# Função auxiliar para segmentar um sinal e adicionar ao dicionário\n",
    "def segmentar_e_adicionar(sinal, metadados, dicionario_alvo, chave_base):\n",
    "    # Verifica se o sinal é longo o suficiente para pelo menos um segmento\n",
    "    if len(sinal) < tamanho_segmento:\n",
    "        # print(f\"Aviso: Sinal da base '{chave_base}' muito curto ({len(sinal)} amostras) para gerar segmentos. Ignorando.\")\n",
    "        return 0\n",
    "\n",
    "    num_segmentos_criados = 0\n",
    "    for i, inicio in enumerate(range(0, len(sinal) - tamanho_segmento + 1, passo)):\n",
    "        segmento = sinal[inicio : inicio + tamanho_segmento]\n",
    "        df_segmento = pd.DataFrame({'amplitude': segmento})\n",
    "\n",
    "        # Adiciona metadados\n",
    "        df_segmento['arquivo_origem'] = metadados['nome_arquivo']\n",
    "        df_segmento['rotacao_rpm'] = metadados['rpm']\n",
    "        df_segmento['tipo_falha'] = metadados['tipo_falha']\n",
    "        df_segmento['diametro_falha'] = metadados['diametro_falha']\n",
    "        df_segmento['local_sensor'] = 'Drive End'\n",
    "\n",
    "        chave_segmento = f\"{chave_base}_seg_{i}\"\n",
    "        dicionario_alvo[chave_segmento] = df_segmento\n",
    "        num_segmentos_criados += 1\n",
    "    return num_segmentos_criados\n",
    "\n",
    "# Loop principal pelos arquivos\n",
    "for pasta_atual, _, arquivos in os.walk(caminho_raiz):\n",
    "    for nome_arquivo in arquivos:\n",
    "        # Processar apenas arquivos .npz\n",
    "        if nome_arquivo.endswith('.npz'):\n",
    "            caminho_completo = os.path.join(pasta_atual, nome_arquivo)\n",
    "\n",
    "            # Decodificação de metadados\n",
    "            nome_sem_ext = nome_arquivo.replace('.npz', '')\n",
    "            partes = nome_sem_ext.split('_')\n",
    "            rpm_str = partes[0]\n",
    "            is_normal = 'Normal' in nome_arquivo\n",
    "\n",
    "            metadados = {\n",
    "                'nome_arquivo': nome_arquivo,\n",
    "                'rpm': int(rpm_str) if rpm_str.isdigit() else 0,\n",
    "                'tipo_falha': 'Normal' if is_normal else mapa_tipo_falha.get(partes[1].split('@')[0], 'Desconhecido'),\n",
    "                'diametro_falha': 'N/A' if is_normal else mapa_diametro_falha.get(partes[2], 'Desconhecido')\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                dados_npz = np.load(caminho_completo)\n",
    "                sensor_cod = 'DE' # Foco apenas no Drive End, como no seu código original\n",
    "\n",
    "                if sensor_cod in dados_npz.files:\n",
    "                    sinal_completo = dados_npz[sensor_cod].ravel()\n",
    "\n",
    "                    if is_normal:\n",
    "                        # DIVIDE O SINAL NORMAL EM 80/20\n",
    "                        ponto_corte = int(len(sinal_completo) * 0.8)\n",
    "                        sinal_treino = sinal_completo[:ponto_corte]\n",
    "                        sinal_teste = sinal_completo[ponto_corte:]\n",
    "\n",
    "                        chave_base_normal = f\"{nome_sem_ext}_{sensor_cod}\"\n",
    "                        segmentar_e_adicionar(sinal_treino, metadados, dicionario_treino, f\"{chave_base_normal}_treino\")\n",
    "                        segmentar_e_adicionar(sinal_teste, metadados, dicionario_teste, f\"{chave_base_normal}_teste\")\n",
    "\n",
    "                    else:\n",
    "                        # Sinais com falha (REAIS) vão inteiramente para o TESTE\n",
    "                        # Lógica de chave para arquivos de falha (igual ao seu original)\n",
    "                        partes_chave = nome_sem_ext.split('_')\n",
    "                        partes_chave[-1] = partes_chave[-1].rstrip('0123456789')\n",
    "                        chave_base_falha = \"_\".join(partes_chave)\n",
    "                        \n",
    "                        # =================================================================\n",
    "                        # MUDANÇA PRINCIPAL AQUI: Envia falhas reais para o dicionario_teste\n",
    "                        # =================================================================\n",
    "                        segmentar_e_adicionar(sinal_completo, metadados, dicionario_teste, chave_base_falha)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "# --- Relatório Final (Atualizado para refletir a nova lógica) ---\n",
    "print(\"\\n--- Processo Concluído! ---\")\n",
    "print(f\"Total de segmentos de TREINO (APENAS 80% normais): {len(dicionario_treino)}\")\n",
    "print(f\"Total de segmentos de TESTE (falhas reais + 20% normais): {len(dicionario_teste)}\")\n",
    "\n",
    "if not dicionario_teste:\n",
    "    print(\"\\nAVISO: O dicionário de teste está vazio. Verifique se os arquivos 'Normal' existem e se os sinais são longos o suficiente.\")\n",
    "\n",
    "if dicionario_treino:\n",
    "    # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_treino) > 0:\n",
    "        chave_exemplo_treino = list(dicionario_treino.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TREINO (chave: '{chave_exemplo_treino}'):\")\n",
    "        print(dicionario_treino[chave_exemplo_treino].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TREINO está vazio.\")\n",
    "\n",
    "if dicionario_teste:\n",
    "     # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_teste) > 0:\n",
    "        chave_exemplo_teste = list(dicionario_teste.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TESTE (chave: '{chave_exemplo_teste}'):\")\n",
    "        print(dicionario_teste[chave_exemplo_teste].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TESTE está vazio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31e9c79b",
   "metadata": {},
   "source": [
    "## Gera os sinais sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc7f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 2: FUNÇÃO DE GERAÇÃO DE DADOS SINTÉTICOS\n",
    "# =============================================================================\n",
    "\n",
    "def gerar_dados_sinteticos_treino(\n",
    "    dicionario_treino,\n",
    "    TAXA_AMOSTRAL,\n",
    "    params_drive_end,\n",
    "    amplitudes_referencia,\n",
    "    multiplicadores=[1, 5, 10],\n",
    "    fases_para_adicionar_rad=[0, np.pi/2, np.pi, 3*np.pi/2],\n",
    "    freq_natural_hz=2800,\n",
    "    damping_ratio=0.1,\n",
    "    duracao_pulso_seg=0.05\n",
    "):\n",
    "    \"\"\"\n",
    "    Gera dados sintéticos de falha a partir de segmentos normais de treino.\n",
    "    Engloba a lógica do \"Bloco 2\" do notebook original.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. FUNÇÕES AUXILIARES INTERNAS (Movidas para dentro da função) ---\n",
    "    def calcular_frequencias_rolamento(n, fr, d, D, phi_graus=0.0):\n",
    "        \"\"\"Calcula as frequências teóricas de falha de um rolamento.\"\"\"\n",
    "        phi_rad = np.deg2rad(phi_graus)\n",
    "        termo_comum = (d / D) * np.cos(phi_rad)\n",
    "        return {\n",
    "            'Pista Externa': (n * fr / 2) * (1 - termo_comum),\n",
    "            'Pista Interna': (n * fr / 2) * (1 + termo_comum),\n",
    "            'Esfera': (D * fr / (2 * d)) * (1 - termo_comum**2)\n",
    "        }\n",
    "\n",
    "    def criar_resposta_impulso(taxa_amostral, freq_natural, damping, duracao_pulso):\n",
    "        \"\"\"\n",
    "        Cria um único pulso de sinusoide amortecida (baseado na Eq. 9 de White).\n",
    "        Agora recebe 'duracao_pulso' como argumento.\n",
    "        \"\"\"\n",
    "        # Duração do pulso (tempo para decair)\n",
    "        n_pontos_pulso = int(duracao_pulso * taxa_amostral)\n",
    "        if n_pontos_pulso == 0:\n",
    "             # Garante que o pulso tenha pelo menos 1 ponto se a duração for muito curta\n",
    "             n_pontos_pulso = 1\n",
    "             \n",
    "        t_pulse = np.linspace(0, duracao_pulso, n_pontos_pulso, endpoint=False)\n",
    "        \n",
    "        # Parâmetros da Equação 9 \n",
    "        A = damping * 2 * np.pi * freq_natural\n",
    "        # Frequência amortecida (omega_d)\n",
    "        omega_d = 2 * np.pi * freq_natural * np.sqrt(1 - damping**2)\n",
    "        \n",
    "        # Gera o pulso (sinusoide amortecida)\n",
    "        pulso = np.exp(-A * t_pulse) * np.sin(omega_d * t_pulse)\n",
    "        \n",
    "        return pulso\n",
    "\n",
    "    # --- 2. IDENTIFICAÇÃO DOS SEGMENTOS NORMAIS DE TREINO ---\n",
    "    segmentos_normais_treino = {\n",
    "        chave: df for chave, df in dicionario_treino.items()\n",
    "        if df['tipo_falha'].iloc[0] == 'Normal'\n",
    "    }\n",
    "    print(f\"Usando {len(segmentos_normais_treino)} segmentos normais de TREINO para gerar dados sintéticos.\")\n",
    "\n",
    "    # --- 3. CRIAÇÃO DA RESPOSTA AO IMPULSO ---\n",
    "    # Cria o pulso de resposta UMA VEZ\n",
    "    resposta_impulso_unitaria = criar_resposta_impulso(\n",
    "        TAXA_AMOSTRAL, \n",
    "        freq_natural_hz, \n",
    "        damping_ratio, \n",
    "        duracao_pulso_seg  # <-- Parâmetro de \"tempo de impulse\"\n",
    "    )\n",
    "    \n",
    "    # Normaliza para que a amplitude seja controlada pelos parâmetros 'amp_ref' e 'mult'\n",
    "    max_abs_val = np.max(np.abs(resposta_impulso_unitaria))\n",
    "    if max_abs_val > 0:\n",
    "        resposta_impulso_unitaria /= max_abs_val\n",
    "\n",
    "    print(f\"Modelo de White (Eq. 9) ativado. Freq. Natural: {freq_natural_hz} Hz, Amortecimento: {damping_ratio}, Duração Pulso: {duracao_pulso_seg}s\")\n",
    "\n",
    "    # --- 4. GERAÇÃO E COMBINAÇÃO DOS SINAIS ---\n",
    "    lista_sinais_treino = []\n",
    "    \n",
    "    for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "        sinal_normal_base = df_normal['amplitude'].values\n",
    "        rpm_atual = df_normal['rotacao_rpm'].iloc[0]\n",
    "        \n",
    "        N_PONTOS = len(sinal_normal_base)\n",
    "        duracao_s = N_PONTOS / TAXA_AMOSTRAL\n",
    "        t = np.linspace(0.0, duracao_s, N_PONTOS, endpoint=False)\n",
    "        \n",
    "        fr_hz = rpm_atual / 60\n",
    "        freqs_teoricas = calcular_frequencias_rolamento(fr=fr_hz, **params_drive_end)\n",
    "        \n",
    "        for tipo_falha_sintetica in ['Pista Externa', 'Pista Interna', 'Esfera']:\n",
    "            freq_teorica = freqs_teoricas[tipo_falha_sintetica]\n",
    "            amp_ref = amplitudes_referencia['Drive End'][tipo_falha_sintetica]\n",
    "\n",
    "            # 1. Crie o TREM DE IMPULSOS\n",
    "            trem_de_impulsos = np.zeros(N_PONTOS)\n",
    "            periodo_falha_seg = 1.0 / freq_teorica\n",
    "            ts_segundos = 1.0 / TAXA_AMOSTRAL\n",
    "            \n",
    "            for t_impacto in np.arange(0, duracao_s, periodo_falha_seg):\n",
    "                idx = int(t_impacto / ts_segundos)\n",
    "                if idx < N_PONTOS:\n",
    "                    trem_de_impulsos[idx] = 1.0\n",
    "            \n",
    "            # 2. CONVOLVA os \"gatilhos\" com a \"resposta\"\n",
    "            sinal_falha_bruto = np.convolve(trem_de_impulsos, resposta_impulso_unitaria, mode='same')\n",
    "                \n",
    "            for mult in multiplicadores: # <-- Parâmetro \"multiplicadores\"\n",
    "                for fase in fases_para_adicionar_rad: # <-- Parâmetro \"fases\"\n",
    "                    amplitude_final = amp_ref * mult\n",
    "                    \n",
    "                    deslocamento_idx = int((fase / (2 * np.pi)) * periodo_falha_seg / ts_segundos)\n",
    "                    sinal_falha_sintetico = np.roll(sinal_falha_bruto, deslocamento_idx) * amplitude_final\n",
    "                    \n",
    "                    sinal_final_combinado = sinal_normal_base + sinal_falha_sintetico\n",
    "                    \n",
    "                    lista_sinais_treino.append({\n",
    "                        'sinal_final': sinal_final_combinado,\n",
    "                        'tipo_falha_adicionada': tipo_falha_sintetica,\n",
    "                        'rpm': rpm_atual,\n",
    "                        'multiplicador_amplitude': mult,\n",
    "                        'fase_adicionada_rad': fase,\n",
    "                        'base_normal': chave_normal\n",
    "                    })\n",
    "\n",
    "    # --- 5. ADIÇÃO DOS SEGMENTOS NORMAIS ORIGINAIS DE TREINO ---\n",
    "    print(f\"\\nAdicionando os {len(segmentos_normais_treino)} segmentos normais de TREINO ao conjunto de dados...\")\n",
    "    for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "        lista_sinais_treino.append({\n",
    "            'sinal_final': df_normal['amplitude'].values,\n",
    "            'tipo_falha_adicionada': 'Normal',\n",
    "            'rpm': df_normal['rotacao_rpm'].iloc[0],\n",
    "            'multiplicador_amplitude': 0,\n",
    "            'fase_adicionada_rad': 0,\n",
    "            'base_normal': chave_normal\n",
    "        })\n",
    "\n",
    "    # --- 6. DATAFRAME INTERMEDIÁRIO COM TODOS OS SINAIS DE TREINO ---\n",
    "    df_sinais_treino = pd.DataFrame(lista_sinais_treino)\n",
    "\n",
    "    print(f\"\\n--- Geração de Dados de Treino Concluída! ---\")\n",
    "    print(f\"Total de {len(df_sinais_treino)} segmentos (sintéticos + normais) gerados para o conjunto de TREINO.\")\n",
    "    print(f\"\\n--- Exemplo do DataFrame de Sinais de Treino Gerado ---\")\n",
    "    print(df_sinais_treino.drop(columns=['sinal_final']).tail())\n",
    "    \n",
    "    return df_sinais_treino"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f063c5",
   "metadata": {},
   "source": [
    "## Extração de atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb030ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 3: FUNÇÃO DE EXTRAÇÃO DE FEATURES\n",
    "# =============================================================================\n",
    "\n",
    "def extrair_features_treino_teste(\n",
    "    df_sinais_treino, \n",
    "    dicionario_teste, \n",
    "    TAXA_AMOSTRAL,\n",
    "    min_freq_pico=50, \n",
    "    max_freq_pico=200\n",
    "):\n",
    "    \"\"\"\n",
    "    Extrai atributos de tempo e frequência dos dados de treino e teste.\n",
    "    Engloba a lógica do \"Bloco 3\" do notebook original.\n",
    "    \"\"\"\n",
    "\n",
    "    # --- 1. FUNÇÕES AUXILIARES INTERNAS (Movidas para dentro da função) ---\n",
    "\n",
    "    # --- DOMÍNIO DO TEMPO ---\n",
    "    def calcular_tf2_std(sinal):\n",
    "        return np.std(sinal)\n",
    "\n",
    "    def calcular_tf3_rms(sinal):\n",
    "        return np.sqrt(np.mean(sinal**2))\n",
    "\n",
    "    def calcular_tf4_fator_forma(sinal):\n",
    "        rms = calcular_tf3_rms(sinal)\n",
    "        media_abs = np.mean(np.abs(sinal))\n",
    "        return rms / media_abs if media_abs != 0 else 0\n",
    "\n",
    "    # --- DOMÍNIO DA FREQUÊNCIA ---\n",
    "    def calcular_features_frequencia(sinal, taxa_amostral):\n",
    "        N = len(sinal)\n",
    "        if N == 0: return 0, 0, 0\n",
    "        espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "        freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "        soma_espectro = np.sum(espectro)\n",
    "        if soma_espectro == 0: return 0, 0, 0\n",
    "        ff2_freq_central = np.sum(freqs * espectro) / soma_espectro\n",
    "        ff3_rms_freq = np.sqrt(np.sum((freqs**2) * espectro) / soma_espectro)\n",
    "        ff4_std_freq = np.sqrt(np.sum(((freqs - ff2_freq_central)**2) * espectro) / soma_espectro)\n",
    "        numerador_ff5 = np.sum(((freqs - ff2_freq_central)**3) * espectro) / soma_espectro\n",
    "        ff5_assimetria = numerador_ff5 / (ff4_std_freq**3) if ff4_std_freq != 0 else 0\n",
    "        return ff2_freq_central, ff3_rms_freq, ff5_assimetria\n",
    "\n",
    "    def calcular_freq_pico_range(sinal, taxa_amostral, min_freq, max_freq):\n",
    "        \"\"\"Calcula a frequência com a maior amplitude (pico) em um range específico.\"\"\"\n",
    "        N = len(sinal)\n",
    "        if N == 0:\n",
    "            return 0\n",
    "\n",
    "        espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "        freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "        \n",
    "        # Parâmetro 'min_freq' e 'max_freq' agora são usados aqui\n",
    "        range_mask = (freqs >= min_freq) & (freqs <= max_freq)\n",
    "\n",
    "        freqs_filtradas = freqs[range_mask]\n",
    "        espectro_filtrado = espectro[range_mask]\n",
    "\n",
    "        if len(espectro_filtrado) == 0:\n",
    "            return 0 \n",
    "\n",
    "        indice_pico = np.argmax(espectro_filtrado)\n",
    "        freq_pico = freqs_filtradas[indice_pico]\n",
    "        return freq_pico\n",
    "\n",
    "    # --- FUNÇÃO PRINCIPAL DE EXTRAÇÃO ---\n",
    "    def extrair_todas_features(sinal, taxa_amostral, min_f, max_f):\n",
    "        tf2 = calcular_tf2_std(sinal)\n",
    "        tf3 = calcular_tf3_rms(sinal)\n",
    "        tf4 = calcular_tf4_fator_forma(sinal)\n",
    "        ff2, ff3, ff5 = calcular_features_frequencia(sinal, taxa_amostral)\n",
    "        \n",
    "        # Passa os parâmetros de range para a função de cálculo de pico\n",
    "        ff_pico_range = calcular_freq_pico_range(sinal, taxa_amostral, min_freq=min_f, max_freq=max_f)\n",
    "\n",
    "        return {\n",
    "            'TF2_std': tf2, 'TF3_rms': tf3, 'TF4_fator_forma': tf4,\n",
    "            'FF2_freq_central': ff2, 'FF3_rms_freq': ff3, 'FF5_assimetria_espectral': ff5,\n",
    "            'FF_pico_50_200Hz': ff_pico_range\n",
    "        }\n",
    "\n",
    "    # =============================================================================\n",
    "    # --- 2. PROCESSAMENTO DO CONJUNTO DE TREINO ---\n",
    "    # =============================================================================\n",
    "    print(\"--- Iniciando extração de atributos do conjunto de TREINO ---\")\n",
    "    lista_de_features_treino = []\n",
    "    for linha in df_sinais_treino.itertuples():\n",
    "        features = extrair_todas_features(\n",
    "            linha.sinal_final, \n",
    "            TAXA_AMOSTRAL, \n",
    "            min_freq_pico, \n",
    "            max_freq_pico\n",
    "        )\n",
    "        features['tipo_falha_adicionada'] = linha.tipo_falha_adicionada\n",
    "        features['rpm'] = linha.rpm\n",
    "        features['multiplicador_amplitude'] = linha.multiplicador_amplitude\n",
    "        features['fase_adicionada_rad'] = linha.fase_adicionada_rad\n",
    "        features['base_normal'] = linha.base_normal\n",
    "        lista_de_features_treino.append(features)\n",
    "\n",
    "    df_treino = pd.DataFrame(lista_de_features_treino)\n",
    "    print(f\"Extração concluída! {len(df_treino)} amostras no df_treino.\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # --- 3. PROCESSAMENTO DO CONJUNTO DE TESTE ---\n",
    "    # =============================================================================\n",
    "    print(\"\\n--- Iniciando extração de atributos do conjunto de TESTE ---\")\n",
    "    lista_de_features_teste = []\n",
    "    for chave, df_segmento in dicionario_teste.items():\n",
    "        sinal = df_segmento['amplitude'].values\n",
    "        features = extrair_todas_features(\n",
    "            sinal, \n",
    "            TAXA_AMOSTRAL, \n",
    "            min_freq_pico, \n",
    "            max_freq_pico\n",
    "        )\n",
    "        features['tipo_falha_adicionada'] = df_segmento['tipo_falha'].iloc[0]\n",
    "        features['rpm'] = df_segmento['rotacao_rpm'].iloc[0]\n",
    "        features['arquivo_origem'] = df_segmento['arquivo_origem'].iloc[0]\n",
    "        lista_de_features_teste.append(features)\n",
    "\n",
    "    df_teste = pd.DataFrame(lista_de_features_teste)\n",
    "    print(f\"Extração concluída! {len(df_teste)} amostras no df_teste.\")\n",
    "\n",
    "    # --- 4. EXIBIÇÃO DOS RESULTADOS ---\n",
    "    print(\"\\n\\n--- AMOSTRA DO df_treino (DADOS TRATADOS PARA TREINAMENTO) ---\")\n",
    "    print(df_treino.head())\n",
    "    print(\"\\n--- INFORMAÇÕES DO df_treino ---\")\n",
    "    df_treino.info()\n",
    "\n",
    "    print(\"\\n\\n--- AMOSTRA DO df_teste (DADOS TRATADOS PARA TESTE) ---\")\n",
    "    print(df_teste.head())\n",
    "    print(\"\\n--- INFORMAÇÕES DO df_teste ---\")\n",
    "    df_teste.info()\n",
    "    \n",
    "    return df_treino, df_teste"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
