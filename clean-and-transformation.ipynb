{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e57204",
   "metadata": {},
   "source": [
    "## Importação dos arquivos e geração dos segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfefd281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a leitura e segmentação dos arquivos em 'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset'...\n",
      "Dados normais serão divididos (80% treino / 20% teste).\n",
      "Dados de falha real irão 100% para o teste.\n",
      "\n",
      "--- Processo Concluído! ---\n",
      "Total de segmentos de TREINO (APENAS 80% normais): 470\n",
      "Total de segmentos de TESTE (falhas reais + 20% normais): 2897\n",
      "\n",
      "Exemplo de um segmento de TREINO (chave: '1730_Normal_DE_treino_seg_0'):\n",
      "   amplitude   arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.014603  1730_Normal.npz         1730     Normal            N/A   \n",
      "1   0.054449  1730_Normal.npz         1730     Normal            N/A   \n",
      "2   0.107646  1730_Normal.npz         1730     Normal            N/A   \n",
      "3   0.133722  1730_Normal.npz         1730     Normal            N/A   \n",
      "4   0.112652  1730_Normal.npz         1730     Normal            N/A   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n",
      "\n",
      "Exemplo de um segmento de TESTE (chave: '1730_B_14_DE_seg_0'):\n",
      "   amplitude      arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.105420  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "1  -0.107370  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "2  -0.163410  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "3   0.118903  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "4   0.184039  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 1: CONFIGURAÇÃO, CARREGAMENTO, DIVISÃO (80/20) E SEGMENTAÇÃO (CORRIGIDO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES GERAIS ---\n",
    "caminho_raiz = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset' # IMPORTANTE: Verifique se este caminho está correto\n",
    "params_drive_end = {'n': 9, 'd': 0.3126, 'D': 1.537, 'phi_graus': 0.0}\n",
    "TAXA_AMOSTRAL = 12000\n",
    "\n",
    "# Dicionários de mapeamento\n",
    "mapa_tipo_falha = {'IR': 'Pista Interna', 'B': 'Esfera', 'OR': 'Pista Externa', 'Normal': 'Normal'}\n",
    "mapa_diametro_falha = {'7': '0.007\"', '14': '0.014\"', '21': '0.021\"'}\n",
    "\n",
    "# --- PARÂMETROS DE SEGMENTAÇÃO ---\n",
    "tamanho_segmento = 4096\n",
    "sobreposicao_percentual = 0.3\n",
    "passo = int(tamanho_segmento * (1 - sobreposicao_percentual))\n",
    "\n",
    "# --- 2. CARREGAMENTO, DIVISÃO E PROCESSAMENTO ---\n",
    "dicionario_treino = {} # Dicionário para 80% dos dados normais\n",
    "dicionario_teste = {} # Dicionário para 20% normais + 100% falhas reais\n",
    "\n",
    "print(f\"Iniciando a leitura e segmentação dos arquivos em '{caminho_raiz}'...\")\n",
    "print(\"Dados normais serão divididos (80% treino / 20% teste).\")\n",
    "print(\"Dados de falha real irão 100% para o teste.\")\n",
    "\n",
    "# Função auxiliar para segmentar um sinal e adicionar ao dicionário\n",
    "def segmentar_e_adicionar(sinal, metadados, dicionario_alvo, chave_base):\n",
    "    # Verifica se o sinal é longo o suficiente para pelo menos um segmento\n",
    "    if len(sinal) < tamanho_segmento:\n",
    "        # print(f\"Aviso: Sinal da base '{chave_base}' muito curto ({len(sinal)} amostras) para gerar segmentos. Ignorando.\")\n",
    "        return 0\n",
    "\n",
    "    num_segmentos_criados = 0\n",
    "    for i, inicio in enumerate(range(0, len(sinal) - tamanho_segmento + 1, passo)):\n",
    "        segmento = sinal[inicio : inicio + tamanho_segmento]\n",
    "        df_segmento = pd.DataFrame({'amplitude': segmento})\n",
    "\n",
    "        # Adiciona metadados\n",
    "        df_segmento['arquivo_origem'] = metadados['nome_arquivo']\n",
    "        df_segmento['rotacao_rpm'] = metadados['rpm']\n",
    "        df_segmento['tipo_falha'] = metadados['tipo_falha']\n",
    "        df_segmento['diametro_falha'] = metadados['diametro_falha']\n",
    "        df_segmento['local_sensor'] = 'Drive End'\n",
    "\n",
    "        chave_segmento = f\"{chave_base}_seg_{i}\"\n",
    "        dicionario_alvo[chave_segmento] = df_segmento\n",
    "        num_segmentos_criados += 1\n",
    "    return num_segmentos_criados\n",
    "\n",
    "# Loop principal pelos arquivos\n",
    "for pasta_atual, _, arquivos in os.walk(caminho_raiz):\n",
    "    for nome_arquivo in arquivos:\n",
    "        # Processar apenas arquivos .npz\n",
    "        if nome_arquivo.endswith('.npz'):\n",
    "            caminho_completo = os.path.join(pasta_atual, nome_arquivo)\n",
    "\n",
    "            # Decodificação de metadados\n",
    "            nome_sem_ext = nome_arquivo.replace('.npz', '')\n",
    "            partes = nome_sem_ext.split('_')\n",
    "            rpm_str = partes[0]\n",
    "            is_normal = 'Normal' in nome_arquivo\n",
    "\n",
    "            metadados = {\n",
    "                'nome_arquivo': nome_arquivo,\n",
    "                'rpm': int(rpm_str) if rpm_str.isdigit() else 0,\n",
    "                'tipo_falha': 'Normal' if is_normal else mapa_tipo_falha.get(partes[1].split('@')[0], 'Desconhecido'),\n",
    "                'diametro_falha': 'N/A' if is_normal else mapa_diametro_falha.get(partes[2], 'Desconhecido')\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                dados_npz = np.load(caminho_completo)\n",
    "                sensor_cod = 'DE' # Foco apenas no Drive End, como no seu código original\n",
    "\n",
    "                if sensor_cod in dados_npz.files:\n",
    "                    sinal_completo = dados_npz[sensor_cod].ravel()\n",
    "\n",
    "                    if is_normal:\n",
    "                        # DIVIDE O SINAL NORMAL EM 80/20\n",
    "                        ponto_corte = int(len(sinal_completo) * 0.8)\n",
    "                        sinal_treino = sinal_completo[:ponto_corte]\n",
    "                        sinal_teste = sinal_completo[ponto_corte:]\n",
    "\n",
    "                        chave_base_normal = f\"{nome_sem_ext}_{sensor_cod}\"\n",
    "                        segmentar_e_adicionar(sinal_treino, metadados, dicionario_treino, f\"{chave_base_normal}_treino\")\n",
    "                        segmentar_e_adicionar(sinal_teste, metadados, dicionario_teste, f\"{chave_base_normal}_teste\")\n",
    "\n",
    "                    else:\n",
    "                        # Sinais com falha (REAIS) vão inteiramente para o TESTE\n",
    "                        # Lógica de chave para arquivos de falha (igual ao seu original)\n",
    "                        partes_chave = nome_sem_ext.split('_')\n",
    "                        partes_chave[-1] = partes_chave[-1].rstrip('0123456789')\n",
    "                        chave_base_falha = \"_\".join(partes_chave)\n",
    "                        \n",
    "                        # =================================================================\n",
    "                        # MUDANÇA PRINCIPAL AQUI: Envia falhas reais para o dicionario_teste\n",
    "                        # =================================================================\n",
    "                        segmentar_e_adicionar(sinal_completo, metadados, dicionario_teste, chave_base_falha)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "# --- Relatório Final (Atualizado para refletir a nova lógica) ---\n",
    "print(\"\\n--- Processo Concluído! ---\")\n",
    "print(f\"Total de segmentos de TREINO (APENAS 80% normais): {len(dicionario_treino)}\")\n",
    "print(f\"Total de segmentos de TESTE (falhas reais + 20% normais): {len(dicionario_teste)}\")\n",
    "\n",
    "if not dicionario_teste:\n",
    "    print(\"\\nAVISO: O dicionário de teste está vazio. Verifique se os arquivos 'Normal' existem e se os sinais são longos o suficiente.\")\n",
    "\n",
    "if dicionario_treino:\n",
    "    # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_treino) > 0:\n",
    "        chave_exemplo_treino = list(dicionario_treino.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TREINO (chave: '{chave_exemplo_treino}'):\")\n",
    "        print(dicionario_treino[chave_exemplo_treino].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TREINO está vazio.\")\n",
    "\n",
    "if dicionario_teste:\n",
    "     # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_teste) > 0:\n",
    "        chave_exemplo_teste = list(dicionario_teste.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TESTE (chave: '{chave_exemplo_teste}'):\")\n",
    "        print(dicionario_teste[chave_exemplo_teste].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TESTE está vazio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f690a",
   "metadata": {},
   "source": [
    "## Criação do sinal sintético de falha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b0aa665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 470 segmentos normais de TREINO para gerar dados sintéticos.\n",
      "Modelo Híbrido ativado. Freq. Natural: 3278 Hz, Amortecimento: 0.1\n",
      "\n",
      "Adicionando os 470 segmentos normais de TREINO ao conjunto de dados...\n",
      "\n",
      "--- Geração de Dados de Treino Concluída! ---\n",
      "Total de 17390 segmentos (sintéticos + normais) gerados para o conjunto de TREINO.\n",
      "\n",
      "--- Exemplo do DataFrame de Sinais de Treino Gerado ---\n",
      "  tipo_falha_adicionada   rpm  multiplicador_amplitude  fase_adicionada_rad  \\\n",
      "0         Pista Externa  1730                        2             0.000000   \n",
      "1         Pista Externa  1730                        2             1.570796   \n",
      "2         Pista Externa  1730                        2             3.141593   \n",
      "3         Pista Externa  1730                        2             4.712389   \n",
      "4         Pista Externa  1730                        5             0.000000   \n",
      "\n",
      "                   base_normal  \n",
      "0  1730_Normal_DE_treino_seg_0  \n",
      "1  1730_Normal_DE_treino_seg_0  \n",
      "2  1730_Normal_DE_treino_seg_0  \n",
      "3  1730_Normal_DE_treino_seg_0  \n",
      "4  1730_Normal_DE_treino_seg_0  \n"
     ]
    }
   ],
   "source": [
    "# (NOVO) Imports adicionados para plotagem\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 2: GERAÇÃO DE DADOS SINTÉTICOS (USANDO APENAS DADOS DE TREINO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. FUNÇÃO PARA CÁLCULO DE FREQUÊNCIA TEÓRICA (ATUALIZADA) ---\n",
    "def calcular_frequencias_rolamento(n, fr, d, D, phi_graus=0.0):\n",
    "    \"\"\"Calcula as frequências teóricas de falha de um rolamento, incluindo FTF.\"\"\"\n",
    "    phi_rad = np.deg2rad(phi_graus)\n",
    "    termo_comum = (d / D) * np.cos(phi_rad)\n",
    "    \n",
    "    # (NOVO) Frequência da Gaiola (Fundamental Train Frequency - FTF)\n",
    "    freq_ftf = (fr / 2) * (1 - termo_comum)\n",
    "    \n",
    "    return {\n",
    "        'Pista Externa': (n * fr / 2) * (1 - termo_comum),\n",
    "        'Pista Interna': (n * fr / 2) * (1 + termo_comum),\n",
    "        'Esfera': (D * fr / (2 * d)) * (1 - termo_comum**2),\n",
    "        'FTF': freq_ftf  # (NOVO) Adicionado ao dicionário\n",
    "    }\n",
    "\n",
    "# --- 2. PARÂMETROS DE GERAÇÃO ---\n",
    "# (Estes são os seus parâmetros mais recentes)\n",
    "amplitudes_referencia = {\n",
    "    'Drive End': {'Esfera': 0.1, 'Pista Interna': 0.1, 'Pista Externa': 0.1}\n",
    "}\n",
    "multiplicadores = [2, 5, 10]\n",
    "fases_para_adicionar_rad = [\n",
    "    0, np.pi/2,\n",
    "    np.pi, 3*np.pi/2\n",
    "]\n",
    "\n",
    "# --- 3. IDENTIFICAÇÃO DOS SEGMENTOS NORMAIS DE TREINO ---\n",
    "segmentos_normais_treino = {\n",
    "    chave: df for chave, df in dicionario_treino.items()\n",
    "    if df['tipo_falha'].iloc[0] == 'Normal'\n",
    "}\n",
    "print(f\"Usando {len(segmentos_normais_treino)} segmentos normais de TREINO para gerar dados sintéticos.\")\n",
    "\n",
    "\n",
    "# --- 4. GERAÇÃO E COMBINAÇÃO DOS SINAIS ---\n",
    "lista_sinais_treino = []\n",
    "\n",
    "# --- PARÂMETROS PARA O MODELO DE WHITE (Eq. 9 / Fig. 5) ---\n",
    "# (Usando o valor de f_n que você mediu)\n",
    "freq_natural_hz = 3278\n",
    "damping_ratio = 0.1 # (Ponto de partida da Figura 5 de White)\n",
    "# (NOVO) Profundidade da modulação para falhas de Pista Interna e Esfera\n",
    "profundidade_modulacao = 0.5 # (Significa 50% de modulação)\n",
    "\n",
    "# --- FUNÇÃO PARA CRIAR A RESPOSTA AO IMPULSO (Decaying Sinusoid) ---\n",
    "def criar_resposta_impulso(taxa_amostral, freq_natural, damping):\n",
    "    \"\"\"\n",
    "    Cria um único pulso de sinusoide amortecida (baseado na Eq. 9 de White).\n",
    "    \"\"\"\n",
    "    # Aumentei para 100ms para garantir que o pulso decaia\n",
    "    duracao_pulso_seg = 0.1 \n",
    "    n_pontos_pulso = int(duracao_pulso_seg * taxa_amostral)\n",
    "    t_pulse = np.linspace(0, duracao_pulso_seg, n_pontos_pulso, endpoint=False)\n",
    "    \n",
    "    A = damping * 2 * np.pi * freq_natural\n",
    "    omega_d = 2 * np.pi * freq_natural * np.sqrt(1 - damping**2)\n",
    "    \n",
    "    pulso = np.exp(-A * t_pulse) * np.sin(omega_d * t_pulse)\n",
    "    return pulso\n",
    "\n",
    "# Cria o pulso de resposta UMA VEZ\n",
    "resposta_impulso_unitaria = criar_resposta_impulso(TAXA_AMOSTRAL, freq_natural_hz, damping_ratio)\n",
    "resposta_impulso_unitaria /= np.max(np.abs(resposta_impulso_unitaria)) # Normaliza\n",
    "\n",
    "print(f\"Modelo Híbrido ativado. Freq. Natural: {freq_natural_hz} Hz, Amortecimento: {damping_ratio}\")\n",
    "\n",
    "# Loop para gerar os sinais com falha sintética a partir dos normais de treino\n",
    "for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "    sinal_normal_base = df_normal['amplitude'].values\n",
    "    rpm_atual = df_normal['rotacao_rpm'].iloc[0]\n",
    "    \n",
    "    N_PONTOS = len(sinal_normal_base)\n",
    "    duracao_s = N_PONTOS / TAXA_AMOSTRAL\n",
    "    t = np.linspace(0.0, duracao_s, N_PONTOS, endpoint=False)\n",
    "    \n",
    "    fr_hz = rpm_atual / 60\n",
    "    freqs_teoricas = calcular_frequencias_rolamento(fr=fr_hz, **params_drive_end)\n",
    "    \n",
    "    for tipo_falha_sintetica in ['Pista Externa', 'Pista Interna', 'Esfera']:\n",
    "        freq_teorica = freqs_teoricas[tipo_falha_sintetica] \n",
    "        amp_ref = amplitudes_referencia['Drive End'][tipo_falha_sintetica]\n",
    "\n",
    "        # ==========================================================\n",
    "        # *** LÓGICA DE SIMULAÇÃO DIFERENCIADA (BASEADA NAS NOVAS REGRAS) ***\n",
    "        \n",
    "        # 1. Crie o TREM DE IMPULSOS (comum a todos)\n",
    "        trem_de_impulsos = np.zeros(N_PONTOS)\n",
    "        periodo_falha_seg = 1.0 / freq_teorica\n",
    "        ts_segundos = 1.0 / TAXA_AMOSTRAL \n",
    "        for t_impacto in np.arange(0, duracao_s, periodo_falha_seg):\n",
    "            idx = int(t_impacto / ts_segundos)\n",
    "            if idx < N_PONTOS:\n",
    "                trem_de_impulsos[idx] = 1.0\n",
    "        \n",
    "        # 2. Gere o sinal de \"RINGING\" excitado pela $f_n$ (comum a todos)\n",
    "        sinal_falha_ringing = np.convolve(trem_de_impulsos, resposta_impulso_unitaria, mode='same')\n",
    "        \n",
    "        # 3. Aplique a MODULAÇÃO DE AMPLITUDE (AM) específica da falha\n",
    "        \n",
    "        if tipo_falha_sintetica == 'Pista Externa':\n",
    "            # Regra: \"no sidebands\" -> Sem modulação de amplitude\n",
    "            sinal_falha_bruto = sinal_falha_ringing\n",
    "        \n",
    "        elif tipo_falha_sintetica == 'Pista Interna':\n",
    "            # Regra: \"sidebands spaced at fr\" -> Modulação pela rotação (fr_hz)\n",
    "            modulador_fr = (1 + profundidade_modulacao * np.sin(2 * np.pi * fr_hz * t))\n",
    "            sinal_falha_bruto = sinal_falha_ringing * modulador_fr\n",
    "            \n",
    "        elif tipo_falha_sintetica == 'Esfera':\n",
    "            # Regra: \"sidebands spaced at FTF\" -> Modulação pela gaiola (FTF)\n",
    "            freq_ftf = freqs_teoricas['FTF']\n",
    "            modulador_ftf = (1 + profundidade_modulacao * np.sin(2 * np.pi * freq_ftf * t))\n",
    "            sinal_falha_bruto = sinal_falha_ringing * modulador_ftf\n",
    "            \n",
    "        # ==========================================================\n",
    "            \n",
    "        for mult in multiplicadores:\n",
    "            for fase in fases_para_adicionar_rad:\n",
    "                amplitude_final = amp_ref * mult\n",
    "                \n",
    "                # Desloca o sinal de falha para simular a fase\n",
    "                deslocamento_idx = int((fase / (2 * np.pi)) * periodo_falha_seg / ts_segundos)\n",
    "                sinal_falha_sintetico = np.roll(sinal_falha_bruto, deslocamento_idx) * amplitude_final\n",
    "                \n",
    "                sinal_final_combinado = sinal_normal_base + sinal_falha_sintetico\n",
    "                \n",
    "                lista_sinais_treino.append({\n",
    "                    'sinal_final': sinal_final_combinado,\n",
    "                    'tipo_falha_adicionada': tipo_falha_sintetica,\n",
    "                    'rpm': rpm_atual,\n",
    "                    'multiplicador_amplitude': mult,\n",
    "                    'fase_adicionada_rad': fase,\n",
    "                    'base_normal': chave_normal\n",
    "                })\n",
    "\n",
    "# --- 5. ADIÇÃO DOS SEGMENTOS NORMAIS ORIGINAIS DE TREINO ---\n",
    "print(f\"\\nAdicionando os {len(segmentos_normais_treino)} segmentos normais de TREINO ao conjunto de dados...\")\n",
    "for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "    lista_sinais_treino.append({\n",
    "        'sinal_final': df_normal['amplitude'].values,\n",
    "        'tipo_falha_adicionada': 'Normal',\n",
    "        'rpm': df_normal['rotacao_rpm'].iloc[0],\n",
    "        'multiplicador_amplitude': 0,\n",
    "        'fase_adicionada_rad': 0,\n",
    "        'base_normal': chave_normal\n",
    "    })\n",
    "\n",
    "# --- 6. DATAFRAME INTERMEDIÁRIO COM TODOS OS SINAIS DE TREINO ---\n",
    "df_sinais_treino = pd.DataFrame(lista_sinais_treino)\n",
    "\n",
    "print(f\"\\n--- Geração de Dados de Treino Concluída! ---\")\n",
    "print(f\"Total de {len(df_sinais_treino)} segmentos (sintéticos + normais) gerados para o conjunto de TREINO.\")\n",
    "print(f\"\\n--- Exemplo do DataFrame de Sinais de Treino Gerado ---\")\n",
    "print(df_sinais_treino.drop(columns=['sinal_final']).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224bb65",
   "metadata": {},
   "source": [
    "## Cálculo dos atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90e3d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando extração de atributos do conjunto de TREINO ---\n",
      "Extração concluída! 17390 amostras no df_treino.\n",
      "\n",
      "--- Iniciando extração de atributos do conjunto de TESTE ---\n",
      "Extração concluída! 2897 amostras no df_teste.\n",
      "\n",
      "\n",
      "--- AMOSTRA DO df_treino (DADOS TRATADOS PARA TREINAMENTO) ---\n",
      "    TF2_std   TF3_rms  TF4_fator_forma  FF2_freq_central  FF3_rms_freq  \\\n",
      "0  0.070003  0.071239         1.266737       1705.195192   2274.701036   \n",
      "1  0.069856  0.071094         1.261392       1706.235559   2278.259140   \n",
      "2  0.069692  0.070933         1.261013       1707.604441   2278.588253   \n",
      "3  0.069963  0.071199         1.261307       1705.362608   2276.421048   \n",
      "4  0.089851  0.090989         1.430602       2257.752506   2788.311502   \n",
      "\n",
      "   FF5_assimetria_espectral  FF_pico_50_200Hz tipo_falha_adicionada   rpm  \\\n",
      "0                  0.916930         90.820312         Pista Externa  1730   \n",
      "1                  0.914737         90.820312         Pista Externa  1730   \n",
      "2                  0.915977         90.820312         Pista Externa  1730   \n",
      "3                  0.917874         90.820312         Pista Externa  1730   \n",
      "4                  0.348342         90.820312         Pista Externa  1730   \n",
      "\n",
      "   multiplicador_amplitude  fase_adicionada_rad                  base_normal  \n",
      "0                        2             0.000000  1730_Normal_DE_treino_seg_0  \n",
      "1                        2             1.570796  1730_Normal_DE_treino_seg_0  \n",
      "2                        2             3.141593  1730_Normal_DE_treino_seg_0  \n",
      "3                        2             4.712389  1730_Normal_DE_treino_seg_0  \n",
      "4                        5             0.000000  1730_Normal_DE_treino_seg_0  \n",
      "\n",
      "--- INFORMAÇÕES DO df_treino ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17390 entries, 0 to 17389\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   TF2_std                   17390 non-null  float64\n",
      " 1   TF3_rms                   17390 non-null  float64\n",
      " 2   TF4_fator_forma           17390 non-null  float64\n",
      " 3   FF2_freq_central          17390 non-null  float64\n",
      " 4   FF3_rms_freq              17390 non-null  float64\n",
      " 5   FF5_assimetria_espectral  17390 non-null  float64\n",
      " 6   FF_pico_50_200Hz          17390 non-null  float64\n",
      " 7   tipo_falha_adicionada     17390 non-null  object \n",
      " 8   rpm                       17390 non-null  int64  \n",
      " 9   multiplicador_amplitude   17390 non-null  int64  \n",
      " 10  fase_adicionada_rad       17390 non-null  float64\n",
      " 11  base_normal               17390 non-null  object \n",
      "dtypes: float64(8), int64(2), object(2)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "\n",
      "--- AMOSTRA DO df_teste (DADOS TRATADOS PARA TESTE) ---\n",
      "    TF2_std   TF3_rms  TF4_fator_forma  FF2_freq_central  FF3_rms_freq  \\\n",
      "0  0.135539  0.135618         1.421284       2492.178998   2757.283107   \n",
      "1  0.144794  0.144867         1.425523       2466.891600   2731.567802   \n",
      "2  0.125087  0.125170         1.370505       2479.452296   2775.305109   \n",
      "3  0.107887  0.107973         1.335885       2552.707103   2860.095547   \n",
      "4  0.110667  0.110750         1.362182       2602.813080   2888.160569   \n",
      "\n",
      "   FF5_assimetria_espectral  FF_pico_50_200Hz tipo_falha_adicionada   rpm  \\\n",
      "0                 -0.320221        155.273438                Esfera  1730   \n",
      "1                 -0.326991        155.273438                Esfera  1730   \n",
      "2                 -0.220875        155.273438                Esfera  1730   \n",
      "3                 -0.220973        155.273438                Esfera  1730   \n",
      "4                 -0.250310        155.273438                Esfera  1730   \n",
      "\n",
      "       arquivo_origem  \n",
      "0  1730_B_14_DE12.npz  \n",
      "1  1730_B_14_DE12.npz  \n",
      "2  1730_B_14_DE12.npz  \n",
      "3  1730_B_14_DE12.npz  \n",
      "4  1730_B_14_DE12.npz  \n",
      "\n",
      "--- INFORMAÇÕES DO df_teste ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2897 entries, 0 to 2896\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   TF2_std                   2897 non-null   float64\n",
      " 1   TF3_rms                   2897 non-null   float64\n",
      " 2   TF4_fator_forma           2897 non-null   float64\n",
      " 3   FF2_freq_central          2897 non-null   float64\n",
      " 4   FF3_rms_freq              2897 non-null   float64\n",
      " 5   FF5_assimetria_espectral  2897 non-null   float64\n",
      " 6   FF_pico_50_200Hz          2897 non-null   float64\n",
      " 7   tipo_falha_adicionada     2897 non-null   object \n",
      " 8   rpm                       2897 non-null   int64  \n",
      " 9   arquivo_origem            2897 non-null   object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 226.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 3: EXTRAÇÃO DE FEATURES E CRIAÇÃO DOS DATAFRAMES FINAIS (ATUALIZADO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. FUNÇÕES PARA CÁLCULO DOS ATRIBUTOS ---\n",
    "\n",
    "# --- DOMÍNIO DO TEMPO ---\n",
    "def calcular_tf2_std(sinal):\n",
    "    return np.std(sinal)\n",
    "\n",
    "def calcular_tf3_rms(sinal):\n",
    "    return np.sqrt(np.mean(sinal**2))\n",
    "\n",
    "def calcular_tf4_fator_forma(sinal):\n",
    "    rms = calcular_tf3_rms(sinal)\n",
    "    media_abs = np.mean(np.abs(sinal))\n",
    "    return rms / media_abs if media_abs != 0 else 0\n",
    "\n",
    "# --- DOMÍNIO DA FREQUÊNCIA ---\n",
    "def calcular_features_frequencia(sinal, taxa_amostral):\n",
    "    N = len(sinal)\n",
    "    if N == 0: return 0, 0, 0\n",
    "    espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "    freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "    soma_espectro = np.sum(espectro)\n",
    "    if soma_espectro == 0: return 0, 0, 0\n",
    "    ff2_freq_central = np.sum(freqs * espectro) / soma_espectro\n",
    "    ff3_rms_freq = np.sqrt(np.sum((freqs**2) * espectro) / soma_espectro)\n",
    "    ff4_std_freq = np.sqrt(np.sum(((freqs - ff2_freq_central)**2) * espectro) / soma_espectro)\n",
    "    numerador_ff5 = np.sum(((freqs - ff2_freq_central)**3) * espectro) / soma_espectro\n",
    "    ff5_assimetria = numerador_ff5 / (ff4_std_freq**3) if ff4_std_freq != 0 else 0\n",
    "    return ff2_freq_central, ff3_rms_freq, ff5_assimetria\n",
    "\n",
    "# ******************************************************************************\n",
    "# *** NOVA FUNÇÃO ADICIONADA AQUI ***\n",
    "def calcular_freq_pico_range(sinal, taxa_amostral, min_freq=50, max_freq=200):\n",
    "    \"\"\"Calcula a frequência com a maior amplitude (pico) em um range específico.\"\"\"\n",
    "    N = len(sinal)\n",
    "    if N == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calcula a FFT e as frequências correspondentes\n",
    "    espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "    freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "\n",
    "    # Cria uma máscara booleana para o range de frequência desejado\n",
    "    range_mask = (freqs >= min_freq) & (freqs <= max_freq)\n",
    "\n",
    "    # Filtra as frequências e o espectro para o range de interesse\n",
    "    freqs_filtradas = freqs[range_mask]\n",
    "    espectro_filtrado = espectro[range_mask]\n",
    "\n",
    "    # Verifica se existe algum valor no espectro filtrado\n",
    "    if len(espectro_filtrado) == 0:\n",
    "        return 0 # Retorna 0 se não houver componentes de frequência no range\n",
    "\n",
    "    # Encontra o índice do pico (valor máximo) no espectro filtrado\n",
    "    indice_pico = np.argmax(espectro_filtrado)\n",
    "\n",
    "    # Retorna a frequência correspondente a esse pico\n",
    "    freq_pico = freqs_filtradas[indice_pico]\n",
    "\n",
    "    return freq_pico\n",
    "# ******************************************************************************\n",
    "\n",
    "\n",
    "# --- FUNÇÃO PRINCIPAL DE EXTRAÇÃO (ATUALIZADA) ---\n",
    "def extrair_todas_features(sinal, taxa_amostral):\n",
    "    # Features anteriores\n",
    "    tf2 = calcular_tf2_std(sinal)\n",
    "    tf3 = calcular_tf3_rms(sinal)\n",
    "    tf4 = calcular_tf4_fator_forma(sinal)\n",
    "    ff2, ff3, ff5 = calcular_features_frequencia(sinal, taxa_amostral)\n",
    "\n",
    "    # *** CÁLCULO DA NOVA FEATURE ***\n",
    "    ff_pico_range = calcular_freq_pico_range(sinal, taxa_amostral, min_freq=50, max_freq=200)\n",
    "\n",
    "    # Retorna o dicionário com a nova feature incluída\n",
    "    return {\n",
    "        'TF2_std': tf2, 'TF3_rms': tf3, 'TF4_fator_forma': tf4,\n",
    "        'FF2_freq_central': ff2, 'FF3_rms_freq': ff3, 'FF5_assimetria_espectral': ff5,\n",
    "        'FF_pico_50_200Hz': ff_pico_range # *** NOVA FEATURE ADICIONADA AQUI ***\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- 2. PROCESSAMENTO DO CONJUNTO DE TREINO (O CÓDIGO AQUI NÃO MUDA) ---\n",
    "# =============================================================================\n",
    "print(\"--- Iniciando extração de atributos do conjunto de TREINO ---\")\n",
    "lista_de_features_treino = []\n",
    "for linha in df_sinais_treino.itertuples():\n",
    "    features = extrair_todas_features(linha.sinal_final, TAXA_AMOSTRAL)\n",
    "    features['tipo_falha_adicionada'] = linha.tipo_falha_adicionada\n",
    "    features['rpm'] = linha.rpm\n",
    "    features['multiplicador_amplitude'] = linha.multiplicador_amplitude\n",
    "    features['fase_adicionada_rad'] = linha.fase_adicionada_rad\n",
    "    features['base_normal'] = linha.base_normal\n",
    "    lista_de_features_treino.append(features)\n",
    "\n",
    "df_treino = pd.DataFrame(lista_de_features_treino)\n",
    "print(f\"Extração concluída! {len(df_treino)} amostras no df_treino.\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- 3. PROCESSAMENTO DO CONJUNTO DE TESTE (O CÓDIGO AQUI NÃO MUDA) ---\n",
    "# =============================================================================\n",
    "print(\"\\n--- Iniciando extração de atributos do conjunto de TESTE ---\")\n",
    "lista_de_features_teste = []\n",
    "for chave, df_segmento in dicionario_teste.items():\n",
    "    sinal = df_segmento['amplitude'].values\n",
    "    features = extrair_todas_features(sinal, TAXA_AMOSTRAL)\n",
    "    features['tipo_falha_adicionada'] = df_segmento['tipo_falha'].iloc[0]\n",
    "    features['rpm'] = df_segmento['rotacao_rpm'].iloc[0]\n",
    "    features['arquivo_origem'] = df_segmento['arquivo_origem'].iloc[0]\n",
    "    lista_de_features_teste.append(features)\n",
    "\n",
    "df_teste = pd.DataFrame(lista_de_features_teste)\n",
    "print(f\"Extração concluída! {len(df_teste)} amostras no df_teste.\")\n",
    "\n",
    "# --- 4. EXIBIÇÃO DOS RESULTADOS ---\n",
    "print(\"\\n\\n--- AMOSTRA DO df_treino (DADOS TRATADOS PARA TREINAMENTO) ---\")\n",
    "print(df_treino.head())\n",
    "print(\"\\n--- INFORMAÇÕES DO df_treino ---\")\n",
    "df_treino.info()\n",
    "\n",
    "print(\"\\n\\n--- AMOSTRA DO df_teste (DADOS TRATADOS PARA TESTE) ---\")\n",
    "print(df_teste.head())\n",
    "print(\"\\n--- INFORMAÇÕES DO df_teste ---\")\n",
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47277d7f",
   "metadata": {},
   "source": [
    "## Salva CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16084aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame de TREINO (features) salvo com sucesso em:\n",
      "C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC\\df_treino_features.csv\n",
      "\n",
      "DataFrame de TESTE (features) salvo com sucesso em:\n",
      "C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC\\df_teste_features.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 4: SALVAR OS DATAFRAMES FINAIS EM CSV (COM CAMINHO ESPECÍFICO)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Caminho de saída EXATO fornecido por você\n",
    "caminho_base_output = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC'\n",
    "\n",
    "# Cria o diretório se ele não existir\n",
    "if not os.path.exists(caminho_base_output):\n",
    "    os.makedirs(caminho_base_output)\n",
    "    print(f\"Diretório criado em: {caminho_base_output}\")\n",
    "\n",
    "# Define os nomes dos arquivos\n",
    "caminho_csv_treino = os.path.join(caminho_base_output, 'df_treino_features.csv')\n",
    "caminho_csv_teste = os.path.join(caminho_base_output, 'df_teste_features.csv')\n",
    "\n",
    "try:\n",
    "    # Salva o DataFrame de treino\n",
    "    df_treino.to_csv(caminho_csv_treino, index=False)\n",
    "    print(f\"\\nDataFrame de TREINO (features) salvo com sucesso em:\")\n",
    "    print(f\"{caminho_csv_treino}\")\n",
    "\n",
    "    # Salva o DataFrame de teste\n",
    "    df_teste.to_csv(caminho_csv_teste, index=False)\n",
    "    print(f\"\\nDataFrame de TESTE (features) salvo com sucesso em:\")\n",
    "    print(f\"{caminho_csv_teste}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERRO: Os DataFrames 'df_treino' ou 'df_teste' não foram encontrados.\")\n",
    "    print(\"Certifique-se de que o Bloco 3 foi executado com sucesso antes de salvar.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado ao salvar os arquivos: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
