{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23e57204",
   "metadata": {},
   "source": [
    "## Importação dos arquivos e geração dos segmentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfefd281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a leitura e segmentação dos arquivos em 'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset'...\n",
      "Dados normais serão divididos (80% treino / 20% teste).\n",
      "Dados de falha real irão 100% para o teste.\n",
      "\n",
      "--- Processo Concluído! ---\n",
      "Total de segmentos de TREINO (APENAS 80% normais): 470\n",
      "Total de segmentos de TESTE (falhas reais + 20% normais): 2897\n",
      "\n",
      "Exemplo de um segmento de TREINO (chave: '1730_Normal_DE_treino_seg_0'):\n",
      "   amplitude   arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.014603  1730_Normal.npz         1730     Normal            N/A   \n",
      "1   0.054449  1730_Normal.npz         1730     Normal            N/A   \n",
      "2   0.107646  1730_Normal.npz         1730     Normal            N/A   \n",
      "3   0.133722  1730_Normal.npz         1730     Normal            N/A   \n",
      "4   0.112652  1730_Normal.npz         1730     Normal            N/A   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n",
      "\n",
      "Exemplo de um segmento de TESTE (chave: '1730_B_14_DE_seg_0'):\n",
      "   amplitude      arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.105420  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "1  -0.107370  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "2  -0.163410  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "3   0.118903  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "4   0.184039  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 1: CONFIGURAÇÃO, CARREGAMENTO, DIVISÃO (80/20) E SEGMENTAÇÃO (CORRIGIDO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES GERAIS ---\n",
    "caminho_raiz = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset' # IMPORTANTE: Verifique se este caminho está correto\n",
    "params_drive_end = {'n': 9, 'd': 0.3126, 'D': 1.537, 'phi_graus': 0.0}\n",
    "TAXA_AMOSTRAL = 12000\n",
    "\n",
    "# Dicionários de mapeamento\n",
    "mapa_tipo_falha = {'IR': 'Pista Interna', 'B': 'Esfera', 'OR': 'Pista Externa', 'Normal': 'Normal'}\n",
    "mapa_diametro_falha = {'7': '0.007\"', '14': '0.014\"', '21': '0.021\"'}\n",
    "\n",
    "# --- PARÂMETROS DE SEGMENTAÇÃO ---\n",
    "tamanho_segmento = 4096\n",
    "sobreposicao_percentual = 0.3\n",
    "passo = int(tamanho_segmento * (1 - sobreposicao_percentual))\n",
    "\n",
    "# --- 2. CARREGAMENTO, DIVISÃO E PROCESSAMENTO ---\n",
    "dicionario_treino = {} # Dicionário para 80% dos dados normais\n",
    "dicionario_teste = {} # Dicionário para 20% normais + 100% falhas reais\n",
    "\n",
    "print(f\"Iniciando a leitura e segmentação dos arquivos em '{caminho_raiz}'...\")\n",
    "print(\"Dados normais serão divididos (80% treino / 20% teste).\")\n",
    "print(\"Dados de falha real irão 100% para o teste.\")\n",
    "\n",
    "# Função auxiliar para segmentar um sinal e adicionar ao dicionário\n",
    "def segmentar_e_adicionar(sinal, metadados, dicionario_alvo, chave_base):\n",
    "    # Verifica se o sinal é longo o suficiente para pelo menos um segmento\n",
    "    if len(sinal) < tamanho_segmento:\n",
    "        # print(f\"Aviso: Sinal da base '{chave_base}' muito curto ({len(sinal)} amostras) para gerar segmentos. Ignorando.\")\n",
    "        return 0\n",
    "\n",
    "    num_segmentos_criados = 0\n",
    "    for i, inicio in enumerate(range(0, len(sinal) - tamanho_segmento + 1, passo)):\n",
    "        segmento = sinal[inicio : inicio + tamanho_segmento]\n",
    "        df_segmento = pd.DataFrame({'amplitude': segmento})\n",
    "\n",
    "        # Adiciona metadados\n",
    "        df_segmento['arquivo_origem'] = metadados['nome_arquivo']\n",
    "        df_segmento['rotacao_rpm'] = metadados['rpm']\n",
    "        df_segmento['tipo_falha'] = metadados['tipo_falha']\n",
    "        df_segmento['diametro_falha'] = metadados['diametro_falha']\n",
    "        df_segmento['local_sensor'] = 'Drive End'\n",
    "\n",
    "        chave_segmento = f\"{chave_base}_seg_{i}\"\n",
    "        dicionario_alvo[chave_segmento] = df_segmento\n",
    "        num_segmentos_criados += 1\n",
    "    return num_segmentos_criados\n",
    "\n",
    "# Loop principal pelos arquivos\n",
    "for pasta_atual, _, arquivos in os.walk(caminho_raiz):\n",
    "    for nome_arquivo in arquivos:\n",
    "        # Processar apenas arquivos .npz\n",
    "        if nome_arquivo.endswith('.npz'):\n",
    "            caminho_completo = os.path.join(pasta_atual, nome_arquivo)\n",
    "\n",
    "            # Decodificação de metadados\n",
    "            nome_sem_ext = nome_arquivo.replace('.npz', '')\n",
    "            partes = nome_sem_ext.split('_')\n",
    "            rpm_str = partes[0]\n",
    "            is_normal = 'Normal' in nome_arquivo\n",
    "\n",
    "            metadados = {\n",
    "                'nome_arquivo': nome_arquivo,\n",
    "                'rpm': int(rpm_str) if rpm_str.isdigit() else 0,\n",
    "                'tipo_falha': 'Normal' if is_normal else mapa_tipo_falha.get(partes[1].split('@')[0], 'Desconhecido'),\n",
    "                'diametro_falha': 'N/A' if is_normal else mapa_diametro_falha.get(partes[2], 'Desconhecido')\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                dados_npz = np.load(caminho_completo)\n",
    "                sensor_cod = 'DE' # Foco apenas no Drive End, como no seu código original\n",
    "\n",
    "                if sensor_cod in dados_npz.files:\n",
    "                    sinal_completo = dados_npz[sensor_cod].ravel()\n",
    "\n",
    "                    if is_normal:\n",
    "                        # DIVIDE O SINAL NORMAL EM 80/20\n",
    "                        ponto_corte = int(len(sinal_completo) * 0.8)\n",
    "                        sinal_treino = sinal_completo[:ponto_corte]\n",
    "                        sinal_teste = sinal_completo[ponto_corte:]\n",
    "\n",
    "                        chave_base_normal = f\"{nome_sem_ext}_{sensor_cod}\"\n",
    "                        segmentar_e_adicionar(sinal_treino, metadados, dicionario_treino, f\"{chave_base_normal}_treino\")\n",
    "                        segmentar_e_adicionar(sinal_teste, metadados, dicionario_teste, f\"{chave_base_normal}_teste\")\n",
    "\n",
    "                    else:\n",
    "                        # Sinais com falha (REAIS) vão inteiramente para o TESTE\n",
    "                        # Lógica de chave para arquivos de falha (igual ao seu original)\n",
    "                        partes_chave = nome_sem_ext.split('_')\n",
    "                        partes_chave[-1] = partes_chave[-1].rstrip('0123456789')\n",
    "                        chave_base_falha = \"_\".join(partes_chave)\n",
    "                        \n",
    "                        # =================================================================\n",
    "                        # MUDANÇA PRINCIPAL AQUI: Envia falhas reais para o dicionario_teste\n",
    "                        # =================================================================\n",
    "                        segmentar_e_adicionar(sinal_completo, metadados, dicionario_teste, chave_base_falha)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "# --- Relatório Final (Atualizado para refletir a nova lógica) ---\n",
    "print(\"\\n--- Processo Concluído! ---\")\n",
    "print(f\"Total de segmentos de TREINO (APENAS 80% normais): {len(dicionario_treino)}\")\n",
    "print(f\"Total de segmentos de TESTE (falhas reais + 20% normais): {len(dicionario_teste)}\")\n",
    "\n",
    "if not dicionario_teste:\n",
    "    print(\"\\nAVISO: O dicionário de teste está vazio. Verifique se os arquivos 'Normal' existem e se os sinais são longos o suficiente.\")\n",
    "\n",
    "if dicionario_treino:\n",
    "    # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_treino) > 0:\n",
    "        chave_exemplo_treino = list(dicionario_treino.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TREINO (chave: '{chave_exemplo_treino}'):\")\n",
    "        print(dicionario_treino[chave_exemplo_treino].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TREINO está vazio.\")\n",
    "\n",
    "if dicionario_teste:\n",
    "     # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_teste) > 0:\n",
    "        chave_exemplo_teste = list(dicionario_teste.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TESTE (chave: '{chave_exemplo_teste}'):\")\n",
    "        print(dicionario_teste[chave_exemplo_teste].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TESTE está vazio.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251f690a",
   "metadata": {},
   "source": [
    "## Criação do sinal sintético de falha "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0aa665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 470 segmentos normais de TREINO para gerar dados sintéticos.\n",
      "Modelo Híbrido ativado. Freq. Natural: 3278 Hz, Amortecimento: 0.1\n",
      "\n",
      "Adicionando os 470 segmentos normais de TREINO ao conjunto de dados...\n",
      "\n",
      "--- Geração de Dados de Treino Concluída! ---\n",
      "Total de 17390 segmentos (sintéticos + normais) gerados para o conjunto de TREINO.\n",
      "\n",
      "--- Exemplo do DataFrame de Sinais de Treino Gerado ---\n",
      "  tipo_falha_adicionada   rpm  multiplicador_amplitude  fase_adicionada_rad  \\\n",
      "0         Pista Externa  1730                        2             0.000000   \n",
      "1         Pista Externa  1730                        2             1.570796   \n",
      "2         Pista Externa  1730                        2             3.141593   \n",
      "3         Pista Externa  1730                        2             4.712389   \n",
      "4         Pista Externa  1730                        5             0.000000   \n",
      "\n",
      "                   base_normal  \n",
      "0  1730_Normal_DE_treino_seg_0  \n",
      "1  1730_Normal_DE_treino_seg_0  \n",
      "2  1730_Normal_DE_treino_seg_0  \n",
      "3  1730_Normal_DE_treino_seg_0  \n",
      "4  1730_Normal_DE_treino_seg_0  \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 2: FUNÇÃO DE GERAÇÃO DE DADOS SINTÉTICOS\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def gerar_sinais_sinteticos(segmentos_normais_treino, \n",
    "                            TAXA_AMOSTRAL, params_drive_end,\n",
    "                            amplitudes_referencia, multiplicadores, fases_para_adicionar_rad,\n",
    "                            # --- Parâmetros do Experimento ---\n",
    "                            freq_natural_hz, \n",
    "                            damping_ratio,\n",
    "                            profundidade_modulacao,\n",
    "                            duracao_pulso_seg):\n",
    "    \"\"\"\n",
    "    Gera o DataFrame de sinais sintéticos com base nos parâmetros de simulação.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f\"Iniciando Geração de Sinais (Freq: {freq_natural_hz} Hz, Damping: {damping_ratio}, Mod: {profundidade_modulacao})\")\n",
    "    \n",
    "    # --- Função Interna para criar a Resposta ao Impulso ---\n",
    "    def criar_resposta_impulso(taxa_amostral, freq_natural, damping, duracao_pulso):\n",
    "        n_pontos_pulso = int(duracao_pulso * taxa_amostral)\n",
    "        t_pulse = np.linspace(0, duracao_pulso, n_pontos_pulso, endpoint=False)\n",
    "        A = damping * 2 * np.pi * freq_natural\n",
    "        omega_d = 2 * np.pi * freq_natural * np.sqrt(1 - damping**2)\n",
    "        pulso = np.exp(-A * t_pulse) * np.sin(omega_d * t_pulse)\n",
    "        return pulso\n",
    "    \n",
    "    # --- 4. GERAÇÃO E COMBINAÇÃO DOS SINAIS ---\n",
    "    lista_sinais_treino = []\n",
    "    \n",
    "    # Cria o pulso de resposta UMA VEZ\n",
    "    resposta_impulso_unitaria = criar_resposta_impulso(TAXA_AMOSTRAL, freq_natural_hz, damping_ratio, duracao_pulso_seg)\n",
    "    if np.max(np.abs(resposta_impulso_unitaria)) > 0:\n",
    "        resposta_impulso_unitaria /= np.max(np.abs(resposta_impulso_unitaria)) # Normaliza\n",
    "\n",
    "    # Loop para gerar os sinais com falha sintética\n",
    "    for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "        sinal_normal_base = df_normal['amplitude'].values\n",
    "        rpm_atual = df_normal['rotacao_rpm'].iloc[0]\n",
    "        \n",
    "        N_PONTOS = len(sinal_normal_base)\n",
    "        duracao_s = N_PONTOS / TAXA_AMOSTRAL\n",
    "        t = np.linspace(0.0, duracao_s, N_PONTOS, endpoint=False)\n",
    "        \n",
    "        fr_hz = rpm_atual / 60\n",
    "        freqs_teoricas = calcular_frequencias_rolamento(fr=fr_hz, **params_drive_end)\n",
    "        \n",
    "        for tipo_falha_sintetica in ['Pista Externa', 'Pista Interna', 'Esfera']:\n",
    "            freq_teorica = freqs_teoricas[tipo_falha_sintetica] \n",
    "            amp_ref = amplitudes_referencia['Drive End'][tipo_falha_sintetica]\n",
    "            \n",
    "            # 1. Crie o TREM DE IMPULSOS\n",
    "            trem_de_impulsos = np.zeros(N_PONTOS)\n",
    "            periodo_falha_seg = 1.0 / freq_teorica\n",
    "            ts_segundos = 1.0 / TAXA_AMOSTRAL \n",
    "            for t_impacto in np.arange(0, duracao_s, periodo_falha_seg):\n",
    "                idx = int(t_impacto / ts_segundos)\n",
    "                if idx < N_PONTOS:\n",
    "                    trem_de_impulsos[idx] = 1.0\n",
    "            \n",
    "            # 2. Gere o sinal de \"RINGING\"\n",
    "            sinal_falha_ringing = np.convolve(trem_de_impulsos, resposta_impulso_unitaria, mode='same')\n",
    "            \n",
    "            # 3. Aplique a MODULAÇÃO DE AMPLITUDE (AM) específica da falha\n",
    "            if tipo_falha_sintetica == 'Pista Externa':\n",
    "                sinal_falha_bruto = sinal_falha_ringing\n",
    "            elif tipo_falha_sintetica == 'Pista Interna':\n",
    "                modulador_fr = (1 + profundidade_modulacao * np.sin(2 * np.pi * fr_hz * t))\n",
    "                sinal_falha_bruto = sinal_falha_ringing * modulador_fr\n",
    "            elif tipo_falha_sintetica == 'Esfera':\n",
    "                freq_ftf = freqs_teoricas['FTF']\n",
    "                modulador_ftf = (1 + profundidade_modulacao * np.sin(2 * np.pi * freq_ftf * t))\n",
    "                sinal_falha_bruto = sinal_falha_ringing * modulador_ftf\n",
    "            \n",
    "            # Loop de multiplicadores e fases\n",
    "            for mult in multiplicadores:\n",
    "                for fase in fases_para_adicionar_rad:\n",
    "                    amplitude_final = amp_ref * mult\n",
    "                    deslocamento_idx = int((fase / (2 * np.pi)) * periodo_falha_seg / ts_segundos)\n",
    "                    sinal_falha_sintetico = np.roll(sinal_falha_bruto, deslocamento_idx) * amplitude_final\n",
    "                    sinal_final_combinado = sinal_normal_base + sinal_falha_sintetico\n",
    "                    \n",
    "                    lista_sinais_treino.append({\n",
    "                        'sinal_final': sinal_final_combinado,\n",
    "                        'tipo_falha_adicionada': tipo_falha_sintetica,\n",
    "                        'rpm': rpm_atual,\n",
    "                        'multiplicador_amplitude': mult,\n",
    "                        'fase_adicionada_rad': fase,\n",
    "                        'base_normal': chave_normal\n",
    "                    })\n",
    "\n",
    "    # --- 5. ADIÇÃO DOS SEGMENTOS NORMAIS ORIGINAIS DE TREINO ---\n",
    "    print(f\"Adicionando {len(segmentos_normais_treino)} segmentos normais de TREINO...\")\n",
    "    for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "        lista_sinais_treino.append({\n",
    "            'sinal_final': df_normal['amplitude'].values,\n",
    "            'tipo_falha_adicionada': 'Normal',\n",
    "            'rpm': df_normal['rotacao_rpm'].iloc[0],\n",
    "            'multiplicador_amplitude': 0,\n",
    "            'fase_adicionada_rad': 0,\n",
    "            'base_normal': chave_normal\n",
    "        })\n",
    "\n",
    "    # --- 6. DATAFRAME INTERMEDIÁRIO COM TODOS OS SINAIS DE TREINO ---\n",
    "    df_sinais_treino = pd.DataFrame(lista_sinais_treino)\n",
    "    \n",
    "    print(f\"Geração de Sinais Concluída. Total de {len(df_sinais_treino)} segmentos.\")\n",
    "    return df_sinais_treino\n",
    "\n",
    "print(\"Função 'gerar_sinais_sinteticos' definida.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a224bb65",
   "metadata": {},
   "source": [
    "## Cálculo dos atributos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e3d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando extração de atributos do conjunto de TREINO ---\n",
      "Extração concluída! 17390 amostras no df_treino.\n",
      "\n",
      "--- Iniciando extração de atributos do conjunto de TESTE ---\n",
      "Extração concluída! 2897 amostras no df_teste.\n",
      "\n",
      "\n",
      "--- AMOSTRA DO df_treino (DADOS TRATADOS PARA TREINAMENTO) ---\n",
      "    TF2_std   TF3_rms  TF4_fator_forma  FF2_freq_central  FF3_rms_freq  \\\n",
      "0  0.070003  0.071239         1.266737       1705.195192   2274.701036   \n",
      "1  0.069856  0.071094         1.261392       1706.235559   2278.259140   \n",
      "2  0.069692  0.070933         1.261013       1707.604441   2278.588253   \n",
      "3  0.069963  0.071199         1.261307       1705.362608   2276.421048   \n",
      "4  0.089851  0.090989         1.430602       2257.752506   2788.311502   \n",
      "\n",
      "   FF5_assimetria_espectral  FF_pico_50_200Hz tipo_falha_adicionada   rpm  \\\n",
      "0                  0.916930         90.820312         Pista Externa  1730   \n",
      "1                  0.914737         90.820312         Pista Externa  1730   \n",
      "2                  0.915977         90.820312         Pista Externa  1730   \n",
      "3                  0.917874         90.820312         Pista Externa  1730   \n",
      "4                  0.348342         90.820312         Pista Externa  1730   \n",
      "\n",
      "   multiplicador_amplitude  fase_adicionada_rad                  base_normal  \n",
      "0                        2             0.000000  1730_Normal_DE_treino_seg_0  \n",
      "1                        2             1.570796  1730_Normal_DE_treino_seg_0  \n",
      "2                        2             3.141593  1730_Normal_DE_treino_seg_0  \n",
      "3                        2             4.712389  1730_Normal_DE_treino_seg_0  \n",
      "4                        5             0.000000  1730_Normal_DE_treino_seg_0  \n",
      "\n",
      "--- INFORMAÇÕES DO df_treino ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 17390 entries, 0 to 17389\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   TF2_std                   17390 non-null  float64\n",
      " 1   TF3_rms                   17390 non-null  float64\n",
      " 2   TF4_fator_forma           17390 non-null  float64\n",
      " 3   FF2_freq_central          17390 non-null  float64\n",
      " 4   FF3_rms_freq              17390 non-null  float64\n",
      " 5   FF5_assimetria_espectral  17390 non-null  float64\n",
      " 6   FF_pico_50_200Hz          17390 non-null  float64\n",
      " 7   tipo_falha_adicionada     17390 non-null  object \n",
      " 8   rpm                       17390 non-null  int64  \n",
      " 9   multiplicador_amplitude   17390 non-null  int64  \n",
      " 10  fase_adicionada_rad       17390 non-null  float64\n",
      " 11  base_normal               17390 non-null  object \n",
      "dtypes: float64(8), int64(2), object(2)\n",
      "memory usage: 1.6+ MB\n",
      "\n",
      "\n",
      "--- AMOSTRA DO df_teste (DADOS TRATADOS PARA TESTE) ---\n",
      "    TF2_std   TF3_rms  TF4_fator_forma  FF2_freq_central  FF3_rms_freq  \\\n",
      "0  0.135539  0.135618         1.421284       2492.178998   2757.283107   \n",
      "1  0.144794  0.144867         1.425523       2466.891600   2731.567802   \n",
      "2  0.125087  0.125170         1.370505       2479.452296   2775.305109   \n",
      "3  0.107887  0.107973         1.335885       2552.707103   2860.095547   \n",
      "4  0.110667  0.110750         1.362182       2602.813080   2888.160569   \n",
      "\n",
      "   FF5_assimetria_espectral  FF_pico_50_200Hz tipo_falha_adicionada   rpm  \\\n",
      "0                 -0.320221        155.273438                Esfera  1730   \n",
      "1                 -0.326991        155.273438                Esfera  1730   \n",
      "2                 -0.220875        155.273438                Esfera  1730   \n",
      "3                 -0.220973        155.273438                Esfera  1730   \n",
      "4                 -0.250310        155.273438                Esfera  1730   \n",
      "\n",
      "       arquivo_origem  \n",
      "0  1730_B_14_DE12.npz  \n",
      "1  1730_B_14_DE12.npz  \n",
      "2  1730_B_14_DE12.npz  \n",
      "3  1730_B_14_DE12.npz  \n",
      "4  1730_B_14_DE12.npz  \n",
      "\n",
      "--- INFORMAÇÕES DO df_teste ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2897 entries, 0 to 2896\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   TF2_std                   2897 non-null   float64\n",
      " 1   TF3_rms                   2897 non-null   float64\n",
      " 2   TF4_fator_forma           2897 non-null   float64\n",
      " 3   FF2_freq_central          2897 non-null   float64\n",
      " 4   FF3_rms_freq              2897 non-null   float64\n",
      " 5   FF5_assimetria_espectral  2897 non-null   float64\n",
      " 6   FF_pico_50_200Hz          2897 non-null   float64\n",
      " 7   tipo_falha_adicionada     2897 non-null   object \n",
      " 8   rpm                       2897 non-null   int64  \n",
      " 9   arquivo_origem            2897 non-null   object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 226.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 3: FUNÇÃO DE EXTRAÇÃO DE FEATURES\n",
    "# =============================================================================\n",
    "import pandas as pd\n",
    "\n",
    "def extrair_features_pipeline(df_sinais_treino, dicionario_teste, TAXA_AMOSTRAL):\n",
    "    \"\"\"\n",
    "    Executa o pipeline de extração de features nos dados de treino e teste.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n--- Iniciando extração de atributos do conjunto de TREINO ---\")\n",
    "    lista_de_features_treino = []\n",
    "    # (Assume que 'extrair_todas_features' foi definida na célula de Funções Auxiliares)\n",
    "    for linha in df_sinais_treino.itertuples():\n",
    "        features = extrair_todas_features(linha.sinal_final, TAXA_AMOSTRAL)\n",
    "        features['tipo_falha_adicionada'] = linha.tipo_falha_adicionada\n",
    "        features['rpm'] = linha.rpm\n",
    "        features['multiplicador_amplitude'] = linha.multiplicador_amplitude\n",
    "        features['fase_adicionada_rad'] = linha.fase_adicionada_rad\n",
    "        features['base_normal'] = linha.base_normal\n",
    "        lista_de_features_treino.append(features)\n",
    "\n",
    "    df_treino = pd.DataFrame(lista_de_features_treino)\n",
    "    print(f\"Extração de Treino concluída! {len(df_treino)} amostras.\")\n",
    "\n",
    "    # =============================================================================\n",
    "    # --- PROCESSAMENTO DO CONJUNTO DE TESTE ---\n",
    "    # =============================================================================\n",
    "    print(\"\\n--- Iniciando extração de atributos do conjunto de TESTE ---\")\n",
    "    lista_de_features_teste = []\n",
    "    for chave, df_segmento in dicionario_teste.items():\n",
    "        sinal = df_segmento['amplitude'].values\n",
    "        features = extrair_todas_features(sinal, TAXA_AMOSTRAL)\n",
    "        features['tipo_falha_adicionada'] = df_segmento['tipo_falha'].iloc[0]\n",
    "        features['rpm'] = df_segmento['rotacao_rpm'].iloc[0]\n",
    "        features['arquivo_origem'] = df_segmento['arquivo_origem'].iloc[0]\n",
    "        lista_de_features_teste.append(features)\n",
    "\n",
    "    df_teste = pd.DataFrame(lista_de_features_teste)\n",
    "    print(f\"Extração de Teste concluída! {len(df_teste)} amostras.\")\n",
    "    \n",
    "    return df_treino, df_teste\n",
    "\n",
    "print(\"Função 'extrair_features_pipeline' definida.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
