{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfefd281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a leitura e segmentação dos arquivos em 'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset'...\n",
      "Dados normais serão divididos (80% treino / 20% teste).\n",
      "Dados de falha real irão 100% para o teste.\n",
      "\n",
      "--- Processo Concluído! ---\n",
      "Total de segmentos de TREINO (APENAS 80% normais): 470\n",
      "Total de segmentos de TESTE (falhas reais + 20% normais): 2897\n",
      "\n",
      "Exemplo de um segmento de TREINO (chave: '1730_Normal_DE_treino_seg_0'):\n",
      "   amplitude   arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.014603  1730_Normal.npz         1730     Normal            N/A   \n",
      "1   0.054449  1730_Normal.npz         1730     Normal            N/A   \n",
      "2   0.107646  1730_Normal.npz         1730     Normal            N/A   \n",
      "3   0.133722  1730_Normal.npz         1730     Normal            N/A   \n",
      "4   0.112652  1730_Normal.npz         1730     Normal            N/A   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n",
      "\n",
      "Exemplo de um segmento de TESTE (chave: '1730_B_14_DE_seg_0'):\n",
      "   amplitude      arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.105420  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "1  -0.107370  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "2  -0.163410  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "3   0.118903  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "4   0.184039  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 1: CONFIGURAÇÃO, CARREGAMENTO, DIVISÃO (80/20) E SEGMENTAÇÃO (CORRIGIDO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES GERAIS ---\n",
    "caminho_raiz = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset' # IMPORTANTE: Verifique se este caminho está correto\n",
    "params_drive_end = {'n': 9, 'd': 0.3126, 'D': 1.537, 'phi_graus': 0.0}\n",
    "TAXA_AMOSTRAL = 12000\n",
    "\n",
    "# Dicionários de mapeamento\n",
    "mapa_tipo_falha = {'IR': 'Pista Interna', 'B': 'Esfera', 'OR': 'Pista Externa', 'Normal': 'Normal'}\n",
    "mapa_diametro_falha = {'7': '0.007\"', '14': '0.014\"', '21': '0.021\"'}\n",
    "\n",
    "# --- PARÂMETROS DE SEGMENTAÇÃO ---\n",
    "tamanho_segmento = 4096\n",
    "sobreposicao_percentual = 0.3\n",
    "passo = int(tamanho_segmento * (1 - sobreposicao_percentual))\n",
    "\n",
    "# --- 2. CARREGAMENTO, DIVISÃO E PROCESSAMENTO ---\n",
    "dicionario_treino = {} # Dicionário para 80% dos dados normais\n",
    "dicionario_teste = {} # Dicionário para 20% normais + 100% falhas reais\n",
    "\n",
    "print(f\"Iniciando a leitura e segmentação dos arquivos em '{caminho_raiz}'...\")\n",
    "print(\"Dados normais serão divididos (80% treino / 20% teste).\")\n",
    "print(\"Dados de falha real irão 100% para o teste.\")\n",
    "\n",
    "# Função auxiliar para segmentar um sinal e adicionar ao dicionário\n",
    "def segmentar_e_adicionar(sinal, metadados, dicionario_alvo, chave_base):\n",
    "    # Verifica se o sinal é longo o suficiente para pelo menos um segmento\n",
    "    if len(sinal) < tamanho_segmento:\n",
    "        # print(f\"Aviso: Sinal da base '{chave_base}' muito curto ({len(sinal)} amostras) para gerar segmentos. Ignorando.\")\n",
    "        return 0\n",
    "\n",
    "    num_segmentos_criados = 0\n",
    "    for i, inicio in enumerate(range(0, len(sinal) - tamanho_segmento + 1, passo)):\n",
    "        segmento = sinal[inicio : inicio + tamanho_segmento]\n",
    "        df_segmento = pd.DataFrame({'amplitude': segmento})\n",
    "\n",
    "        # Adiciona metadados\n",
    "        df_segmento['arquivo_origem'] = metadados['nome_arquivo']\n",
    "        df_segmento['rotacao_rpm'] = metadados['rpm']\n",
    "        df_segmento['tipo_falha'] = metadados['tipo_falha']\n",
    "        df_segmento['diametro_falha'] = metadados['diametro_falha']\n",
    "        df_segmento['local_sensor'] = 'Drive End'\n",
    "\n",
    "        chave_segmento = f\"{chave_base}_seg_{i}\"\n",
    "        dicionario_alvo[chave_segmento] = df_segmento\n",
    "        num_segmentos_criados += 1\n",
    "    return num_segmentos_criados\n",
    "\n",
    "# Loop principal pelos arquivos\n",
    "for pasta_atual, _, arquivos in os.walk(caminho_raiz):\n",
    "    for nome_arquivo in arquivos:\n",
    "        # Processar apenas arquivos .npz\n",
    "        if nome_arquivo.endswith('.npz'):\n",
    "            caminho_completo = os.path.join(pasta_atual, nome_arquivo)\n",
    "\n",
    "            # Decodificação de metadados\n",
    "            nome_sem_ext = nome_arquivo.replace('.npz', '')\n",
    "            partes = nome_sem_ext.split('_')\n",
    "            rpm_str = partes[0]\n",
    "            is_normal = 'Normal' in nome_arquivo\n",
    "\n",
    "            metadados = {\n",
    "                'nome_arquivo': nome_arquivo,\n",
    "                'rpm': int(rpm_str) if rpm_str.isdigit() else 0,\n",
    "                'tipo_falha': 'Normal' if is_normal else mapa_tipo_falha.get(partes[1].split('@')[0], 'Desconhecido'),\n",
    "                'diametro_falha': 'N/A' if is_normal else mapa_diametro_falha.get(partes[2], 'Desconhecido')\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                dados_npz = np.load(caminho_completo)\n",
    "                sensor_cod = 'DE' # Foco apenas no Drive End, como no seu código original\n",
    "\n",
    "                if sensor_cod in dados_npz.files:\n",
    "                    sinal_completo = dados_npz[sensor_cod].ravel()\n",
    "\n",
    "                    if is_normal:\n",
    "                        # DIVIDE O SINAL NORMAL EM 80/20\n",
    "                        ponto_corte = int(len(sinal_completo) * 0.8)\n",
    "                        sinal_treino = sinal_completo[:ponto_corte]\n",
    "                        sinal_teste = sinal_completo[ponto_corte:]\n",
    "\n",
    "                        chave_base_normal = f\"{nome_sem_ext}_{sensor_cod}\"\n",
    "                        segmentar_e_adicionar(sinal_treino, metadados, dicionario_treino, f\"{chave_base_normal}_treino\")\n",
    "                        segmentar_e_adicionar(sinal_teste, metadados, dicionario_teste, f\"{chave_base_normal}_teste\")\n",
    "\n",
    "                    else:\n",
    "                        # Sinais com falha (REAIS) vão inteiramente para o TESTE\n",
    "                        # Lógica de chave para arquivos de falha (igual ao seu original)\n",
    "                        partes_chave = nome_sem_ext.split('_')\n",
    "                        partes_chave[-1] = partes_chave[-1].rstrip('0123456789')\n",
    "                        chave_base_falha = \"_\".join(partes_chave)\n",
    "                        \n",
    "                        # =================================================================\n",
    "                        # MUDANÇA PRINCIPAL AQUI: Envia falhas reais para o dicionario_teste\n",
    "                        # =================================================================\n",
    "                        segmentar_e_adicionar(sinal_completo, metadados, dicionario_teste, chave_base_falha)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "# --- Relatório Final (Atualizado para refletir a nova lógica) ---\n",
    "print(\"\\n--- Processo Concluído! ---\")\n",
    "print(f\"Total de segmentos de TREINO (APENAS 80% normais): {len(dicionario_treino)}\")\n",
    "print(f\"Total de segmentos de TESTE (falhas reais + 20% normais): {len(dicionario_teste)}\")\n",
    "\n",
    "if not dicionario_teste:\n",
    "    print(\"\\nAVISO: O dicionário de teste está vazio. Verifique se os arquivos 'Normal' existem e se os sinais são longos o suficiente.\")\n",
    "\n",
    "if dicionario_treino:\n",
    "    # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_treino) > 0:\n",
    "        chave_exemplo_treino = list(dicionario_treino.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TREINO (chave: '{chave_exemplo_treino}'):\")\n",
    "        print(dicionario_treino[chave_exemplo_treino].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TREINO está vazio.\")\n",
    "\n",
    "if dicionario_teste:\n",
    "     # Garante que dicionário não está vazio antes de tentar acessar\n",
    "    if len(dicionario_teste) > 0:\n",
    "        chave_exemplo_teste = list(dicionario_teste.keys())[0]\n",
    "        print(f\"\\nExemplo de um segmento de TESTE (chave: '{chave_exemplo_teste}'):\")\n",
    "        print(dicionario_teste[chave_exemplo_teste].head())\n",
    "    else:\n",
    "        print(\"\\nO dicionário de TESTE está vazio.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b0aa665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 470 segmentos normais de TREINO para gerar dados sintéticos.\n",
      "Adicionando os 470 segmentos normais de TREINO ao conjunto de dados...\n",
      "\n",
      "--- Geração de Dados de Treino Concluída! ---\n",
      "Total de 135830 segmentos (sintéticos + normais) gerados para o conjunto de TREINO.\n",
      "\n",
      "--- Exemplo do DataFrame de Sinais de Treino Gerado ---\n",
      "       tipo_falha_adicionada   rpm  multiplicador_amplitude  \\\n",
      "135825                Normal  1797                      0.0   \n",
      "135826                Normal  1797                      0.0   \n",
      "135827                Normal  1797                      0.0   \n",
      "135828                Normal  1797                      0.0   \n",
      "135829                Normal  1797                      0.0   \n",
      "\n",
      "        fase_adicionada_rad                   base_normal  \n",
      "135825                  0.0  1797_Normal_DE_treino_seg_62  \n",
      "135826                  0.0  1797_Normal_DE_treino_seg_63  \n",
      "135827                  0.0  1797_Normal_DE_treino_seg_64  \n",
      "135828                  0.0  1797_Normal_DE_treino_seg_65  \n",
      "135829                  0.0  1797_Normal_DE_treino_seg_66  \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 2: GERAÇÃO DE DADOS SINTÉTICOS (USANDO APENAS DADOS DE TREINO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. FUNÇÃO PARA CÁLCULO DE FREQUÊNCIA TEÓRICA ---\n",
    "def calcular_frequencias_rolamento(n, fr, d, D, phi_graus=0.0):\n",
    "    \"\"\"Calcula as frequências teóricas de falha de um rolamento.\"\"\"\n",
    "    phi_rad = np.deg2rad(phi_graus)\n",
    "    termo_comum = (d / D) * np.cos(phi_rad)\n",
    "    return {\n",
    "        'Pista Externa': (n * fr / 2) * (1 - termo_comum),\n",
    "        'Pista Interna': (n * fr / 2) * (1 + termo_comum),\n",
    "        'Esfera': (D * fr / (2 * d)) * (1 - termo_comum**2)\n",
    "    }\n",
    "\n",
    "# --- 2. PARÂMETROS DE GERAÇÃO ---\n",
    "amplitudes_referencia = {\n",
    "    'Drive End': {'Esfera': 0.0001, 'Pista Interna': 0.001, 'Pista Externa': 0.0001}\n",
    "}\n",
    "multiplicadores = [0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 5.0, 10.0, 25.0, 50.0, 100.0]\n",
    "fases_para_adicionar_rad = [\n",
    "    0, np.pi/4, np.pi/2, 3*np.pi/4,\n",
    "    np.pi, 5*np.pi/4, 3*np.pi/2, 7*np.pi/4\n",
    "]\n",
    "\n",
    "# --- 3. IDENTIFICAÇÃO DOS SEGMENTOS NORMAIS DE TREINO ---\n",
    "# Usamos apenas os dados normais do dicionário de TREINO\n",
    "segmentos_normais_treino = {\n",
    "    chave: df for chave, df in dicionario_treino.items()\n",
    "    if df['tipo_falha'].iloc[0] == 'Normal'\n",
    "}\n",
    "print(f\"Usando {len(segmentos_normais_treino)} segmentos normais de TREINO para gerar dados sintéticos.\")\n",
    "\n",
    "# --- 4. GERAÇÃO E COMBINAÇÃO DOS SINAIS ---\n",
    "lista_sinais_treino = []\n",
    "\n",
    "# Loop para gerar os sinais com falha sintética a partir dos normais de treino\n",
    "for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "    sinal_normal_base = df_normal['amplitude'].values\n",
    "    rpm_atual = df_normal['rotacao_rpm'].iloc[0]\n",
    "    \n",
    "    N_PONTOS = len(sinal_normal_base)\n",
    "    duracao_s = N_PONTOS / TAXA_AMOSTRAL\n",
    "    t = np.linspace(0.0, duracao_s, N_PONTOS, endpoint=False)\n",
    "    \n",
    "    fr_hz = rpm_atual / 60\n",
    "    freqs_teoricas = calcular_frequencias_rolamento(fr=fr_hz, **params_drive_end)\n",
    "    \n",
    "    for tipo_falha_sintetica in ['Pista Externa', 'Pista Interna', 'Esfera']:\n",
    "        freq_teorica = freqs_teoricas[tipo_falha_sintetica]\n",
    "        amp_ref = amplitudes_referencia['Drive End'][tipo_falha_sintetica]\n",
    "            \n",
    "        for mult in multiplicadores:\n",
    "            for fase in fases_para_adicionar_rad:\n",
    "                amplitude_final = amp_ref * mult\n",
    "                sinal_falha_sintetico = amplitude_final * np.sin(2 * np.pi * freq_teorica * t + fase)\n",
    "                sinal_final_combinado = sinal_normal_base + sinal_falha_sintetico\n",
    "                \n",
    "                lista_sinais_treino.append({\n",
    "                    'sinal_final': sinal_final_combinado,\n",
    "                    'tipo_falha_adicionada': tipo_falha_sintetica,\n",
    "                    'rpm': rpm_atual,\n",
    "                    'multiplicador_amplitude': mult,\n",
    "                    'fase_adicionada_rad': fase,\n",
    "                    'base_normal': chave_normal\n",
    "                })\n",
    "\n",
    "# --- 5. ADIÇÃO DOS SEGMENTOS NORMAIS ORIGINAIS DE TREINO ---\n",
    "print(f\"Adicionando os {len(segmentos_normais_treino)} segmentos normais de TREINO ao conjunto de dados...\")\n",
    "for chave_normal, df_normal in segmentos_normais_treino.items():\n",
    "    lista_sinais_treino.append({\n",
    "        'sinal_final': df_normal['amplitude'].values,\n",
    "        'tipo_falha_adicionada': 'Normal',\n",
    "        'rpm': df_normal['rotacao_rpm'].iloc[0],\n",
    "        'multiplicador_amplitude': 0,\n",
    "        'fase_adicionada_rad': 0,\n",
    "        'base_normal': chave_normal\n",
    "    })\n",
    "\n",
    "# --- 6. DATAFRAME INTERMEDIÁRIO COM TODOS OS SINAIS DE TREINO ---\n",
    "df_sinais_treino = pd.DataFrame(lista_sinais_treino)\n",
    "\n",
    "print(f\"\\n--- Geração de Dados de Treino Concluída! ---\")\n",
    "print(f\"Total de {len(df_sinais_treino)} segmentos (sintéticos + normais) gerados para o conjunto de TREINO.\")\n",
    "print(f\"\\n--- Exemplo do DataFrame de Sinais de Treino Gerado ---\")\n",
    "print(df_sinais_treino.drop(columns=['sinal_final']).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90e3d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando extração de atributos do conjunto de TREINO ---\n",
      "Extração concluída! 135830 amostras no df_treino.\n",
      "\n",
      "--- Iniciando extração de atributos do conjunto de TESTE ---\n",
      "Extração concluída! 2897 amostras no df_teste.\n",
      "\n",
      "\n",
      "--- AMOSTRA DO df_treino (DADOS TRATADOS PARA TREINAMENTO) ---\n",
      "    TF2_std   TF3_rms  TF4_fator_forma  FF2_freq_central  FF3_rms_freq  \\\n",
      "0  0.065466  0.066641         1.241618       1098.057364   1513.806757   \n",
      "1  0.065467  0.066641         1.241616       1098.049953   1513.798892   \n",
      "2  0.065467  0.066641         1.241615       1098.046536   1513.794191   \n",
      "3  0.065467  0.066641         1.241616       1098.049110   1513.795407   \n",
      "4  0.065466  0.066640         1.241617       1098.056175   1513.801831   \n",
      "\n",
      "   FF5_assimetria_espectral  FF_pico_50_200Hz tipo_falha_adicionada   rpm  \\\n",
      "0                  1.737825         90.820312         Pista Externa  1730   \n",
      "1                  1.737824         90.820312         Pista Externa  1730   \n",
      "2                  1.737820         90.820312         Pista Externa  1730   \n",
      "3                  1.737817         90.820312         Pista Externa  1730   \n",
      "4                  1.737816         90.820312         Pista Externa  1730   \n",
      "\n",
      "   multiplicador_amplitude  fase_adicionada_rad                  base_normal  \n",
      "0                      0.1             0.000000  1730_Normal_DE_treino_seg_0  \n",
      "1                      0.1             0.785398  1730_Normal_DE_treino_seg_0  \n",
      "2                      0.1             1.570796  1730_Normal_DE_treino_seg_0  \n",
      "3                      0.1             2.356194  1730_Normal_DE_treino_seg_0  \n",
      "4                      0.1             3.141593  1730_Normal_DE_treino_seg_0  \n",
      "\n",
      "--- INFORMAÇÕES DO df_treino ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 135830 entries, 0 to 135829\n",
      "Data columns (total 12 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   TF2_std                   135830 non-null  float64\n",
      " 1   TF3_rms                   135830 non-null  float64\n",
      " 2   TF4_fator_forma           135830 non-null  float64\n",
      " 3   FF2_freq_central          135830 non-null  float64\n",
      " 4   FF3_rms_freq              135830 non-null  float64\n",
      " 5   FF5_assimetria_espectral  135830 non-null  float64\n",
      " 6   FF_pico_50_200Hz          135830 non-null  float64\n",
      " 7   tipo_falha_adicionada     135830 non-null  object \n",
      " 8   rpm                       135830 non-null  int64  \n",
      " 9   multiplicador_amplitude   135830 non-null  float64\n",
      " 10  fase_adicionada_rad       135830 non-null  float64\n",
      " 11  base_normal               135830 non-null  object \n",
      "dtypes: float64(9), int64(1), object(2)\n",
      "memory usage: 12.4+ MB\n",
      "\n",
      "\n",
      "--- AMOSTRA DO df_teste (DADOS TRATADOS PARA TESTE) ---\n",
      "    TF2_std   TF3_rms  TF4_fator_forma  FF2_freq_central  FF3_rms_freq  \\\n",
      "0  0.135539  0.135618         1.421284       2492.178998   2757.283107   \n",
      "1  0.144794  0.144867         1.425523       2466.891600   2731.567802   \n",
      "2  0.125087  0.125170         1.370505       2479.452296   2775.305109   \n",
      "3  0.107887  0.107973         1.335885       2552.707103   2860.095547   \n",
      "4  0.110667  0.110750         1.362182       2602.813080   2888.160569   \n",
      "\n",
      "   FF5_assimetria_espectral  FF_pico_50_200Hz tipo_falha_adicionada   rpm  \\\n",
      "0                 -0.320221        155.273438                Esfera  1730   \n",
      "1                 -0.326991        155.273438                Esfera  1730   \n",
      "2                 -0.220875        155.273438                Esfera  1730   \n",
      "3                 -0.220973        155.273438                Esfera  1730   \n",
      "4                 -0.250310        155.273438                Esfera  1730   \n",
      "\n",
      "       arquivo_origem  \n",
      "0  1730_B_14_DE12.npz  \n",
      "1  1730_B_14_DE12.npz  \n",
      "2  1730_B_14_DE12.npz  \n",
      "3  1730_B_14_DE12.npz  \n",
      "4  1730_B_14_DE12.npz  \n",
      "\n",
      "--- INFORMAÇÕES DO df_teste ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2897 entries, 0 to 2896\n",
      "Data columns (total 10 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   TF2_std                   2897 non-null   float64\n",
      " 1   TF3_rms                   2897 non-null   float64\n",
      " 2   TF4_fator_forma           2897 non-null   float64\n",
      " 3   FF2_freq_central          2897 non-null   float64\n",
      " 4   FF3_rms_freq              2897 non-null   float64\n",
      " 5   FF5_assimetria_espectral  2897 non-null   float64\n",
      " 6   FF_pico_50_200Hz          2897 non-null   float64\n",
      " 7   tipo_falha_adicionada     2897 non-null   object \n",
      " 8   rpm                       2897 non-null   int64  \n",
      " 9   arquivo_origem            2897 non-null   object \n",
      "dtypes: float64(7), int64(1), object(2)\n",
      "memory usage: 226.5+ KB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 3: EXTRAÇÃO DE FEATURES E CRIAÇÃO DOS DATAFRAMES FINAIS (ATUALIZADO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. FUNÇÕES PARA CÁLCULO DOS ATRIBUTOS ---\n",
    "\n",
    "# --- DOMÍNIO DO TEMPO ---\n",
    "def calcular_tf2_std(sinal):\n",
    "    return np.std(sinal)\n",
    "\n",
    "def calcular_tf3_rms(sinal):\n",
    "    return np.sqrt(np.mean(sinal**2))\n",
    "\n",
    "def calcular_tf4_fator_forma(sinal):\n",
    "    rms = calcular_tf3_rms(sinal)\n",
    "    media_abs = np.mean(np.abs(sinal))\n",
    "    return rms / media_abs if media_abs != 0 else 0\n",
    "\n",
    "# --- DOMÍNIO DA FREQUÊNCIA ---\n",
    "def calcular_features_frequencia(sinal, taxa_amostral):\n",
    "    N = len(sinal)\n",
    "    if N == 0: return 0, 0, 0\n",
    "    espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "    freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "    soma_espectro = np.sum(espectro)\n",
    "    if soma_espectro == 0: return 0, 0, 0\n",
    "    ff2_freq_central = np.sum(freqs * espectro) / soma_espectro\n",
    "    ff3_rms_freq = np.sqrt(np.sum((freqs**2) * espectro) / soma_espectro)\n",
    "    ff4_std_freq = np.sqrt(np.sum(((freqs - ff2_freq_central)**2) * espectro) / soma_espectro)\n",
    "    numerador_ff5 = np.sum(((freqs - ff2_freq_central)**3) * espectro) / soma_espectro\n",
    "    ff5_assimetria = numerador_ff5 / (ff4_std_freq**3) if ff4_std_freq != 0 else 0\n",
    "    return ff2_freq_central, ff3_rms_freq, ff5_assimetria\n",
    "\n",
    "# ******************************************************************************\n",
    "# *** NOVA FUNÇÃO ADICIONADA AQUI ***\n",
    "def calcular_freq_pico_range(sinal, taxa_amostral, min_freq=50, max_freq=200):\n",
    "    \"\"\"Calcula a frequência com a maior amplitude (pico) em um range específico.\"\"\"\n",
    "    N = len(sinal)\n",
    "    if N == 0:\n",
    "        return 0\n",
    "\n",
    "    # Calcula a FFT e as frequências correspondentes\n",
    "    espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "    freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "\n",
    "    # Cria uma máscara booleana para o range de frequência desejado\n",
    "    range_mask = (freqs >= min_freq) & (freqs <= max_freq)\n",
    "\n",
    "    # Filtra as frequências e o espectro para o range de interesse\n",
    "    freqs_filtradas = freqs[range_mask]\n",
    "    espectro_filtrado = espectro[range_mask]\n",
    "\n",
    "    # Verifica se existe algum valor no espectro filtrado\n",
    "    if len(espectro_filtrado) == 0:\n",
    "        return 0 # Retorna 0 se não houver componentes de frequência no range\n",
    "\n",
    "    # Encontra o índice do pico (valor máximo) no espectro filtrado\n",
    "    indice_pico = np.argmax(espectro_filtrado)\n",
    "\n",
    "    # Retorna a frequência correspondente a esse pico\n",
    "    freq_pico = freqs_filtradas[indice_pico]\n",
    "\n",
    "    return freq_pico\n",
    "# ******************************************************************************\n",
    "\n",
    "\n",
    "# --- FUNÇÃO PRINCIPAL DE EXTRAÇÃO (ATUALIZADA) ---\n",
    "def extrair_todas_features(sinal, taxa_amostral):\n",
    "    # Features anteriores\n",
    "    tf2 = calcular_tf2_std(sinal)\n",
    "    tf3 = calcular_tf3_rms(sinal)\n",
    "    tf4 = calcular_tf4_fator_forma(sinal)\n",
    "    ff2, ff3, ff5 = calcular_features_frequencia(sinal, taxa_amostral)\n",
    "\n",
    "    # *** CÁLCULO DA NOVA FEATURE ***\n",
    "    ff_pico_range = calcular_freq_pico_range(sinal, taxa_amostral, min_freq=50, max_freq=200)\n",
    "\n",
    "    # Retorna o dicionário com a nova feature incluída\n",
    "    return {\n",
    "        'TF2_std': tf2, 'TF3_rms': tf3, 'TF4_fator_forma': tf4,\n",
    "        'FF2_freq_central': ff2, 'FF3_rms_freq': ff3, 'FF5_assimetria_espectral': ff5,\n",
    "        'FF_pico_50_200Hz': ff_pico_range # *** NOVA FEATURE ADICIONADA AQUI ***\n",
    "    }\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# --- 2. PROCESSAMENTO DO CONJUNTO DE TREINO (O CÓDIGO AQUI NÃO MUDA) ---\n",
    "# =============================================================================\n",
    "print(\"--- Iniciando extração de atributos do conjunto de TREINO ---\")\n",
    "lista_de_features_treino = []\n",
    "for linha in df_sinais_treino.itertuples():\n",
    "    features = extrair_todas_features(linha.sinal_final, TAXA_AMOSTRAL)\n",
    "    features['tipo_falha_adicionada'] = linha.tipo_falha_adicionada\n",
    "    features['rpm'] = linha.rpm\n",
    "    features['multiplicador_amplitude'] = linha.multiplicador_amplitude\n",
    "    features['fase_adicionada_rad'] = linha.fase_adicionada_rad\n",
    "    features['base_normal'] = linha.base_normal\n",
    "    lista_de_features_treino.append(features)\n",
    "\n",
    "df_treino = pd.DataFrame(lista_de_features_treino)\n",
    "print(f\"Extração concluída! {len(df_treino)} amostras no df_treino.\")\n",
    "\n",
    "# =============================================================================\n",
    "# --- 3. PROCESSAMENTO DO CONJUNTO DE TESTE (O CÓDIGO AQUI NÃO MUDA) ---\n",
    "# =============================================================================\n",
    "print(\"\\n--- Iniciando extração de atributos do conjunto de TESTE ---\")\n",
    "lista_de_features_teste = []\n",
    "for chave, df_segmento in dicionario_teste.items():\n",
    "    sinal = df_segmento['amplitude'].values\n",
    "    features = extrair_todas_features(sinal, TAXA_AMOSTRAL)\n",
    "    features['tipo_falha_adicionada'] = df_segmento['tipo_falha'].iloc[0]\n",
    "    features['rpm'] = df_segmento['rotacao_rpm'].iloc[0]\n",
    "    features['arquivo_origem'] = df_segmento['arquivo_origem'].iloc[0]\n",
    "    lista_de_features_teste.append(features)\n",
    "\n",
    "df_teste = pd.DataFrame(lista_de_features_teste)\n",
    "print(f\"Extração concluída! {len(df_teste)} amostras no df_teste.\")\n",
    "\n",
    "# --- 4. EXIBIÇÃO DOS RESULTADOS ---\n",
    "print(\"\\n\\n--- AMOSTRA DO df_treino (DADOS TRATADOS PARA TREINAMENTO) ---\")\n",
    "print(df_treino.head())\n",
    "print(\"\\n--- INFORMAÇÕES DO df_treino ---\")\n",
    "df_treino.info()\n",
    "\n",
    "print(\"\\n\\n--- AMOSTRA DO df_teste (DADOS TRATADOS PARA TESTE) ---\")\n",
    "print(df_teste.head())\n",
    "print(\"\\n--- INFORMAÇÕES DO df_teste ---\")\n",
    "df_teste.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d77fb6c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame de TREINO (features) salvo com sucesso em:\n",
      "C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC\\df_treino_features.csv\n",
      "\n",
      "DataFrame de TESTE (features) salvo com sucesso em:\n",
      "C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC\\df_teste_features.csv\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO 4: SALVAR OS DATAFRAMES FINAIS EM CSV (COM CAMINHO ESPECÍFICO)\n",
    "# =============================================================================\n",
    "\n",
    "import os\n",
    "\n",
    "# Caminho de saída EXATO fornecido por você\n",
    "caminho_base_output = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset\\TCC'\n",
    "\n",
    "# Cria o diretório se ele não existir\n",
    "if not os.path.exists(caminho_base_output):\n",
    "    os.makedirs(caminho_base_output)\n",
    "    print(f\"Diretório criado em: {caminho_base_output}\")\n",
    "\n",
    "# Define os nomes dos arquivos\n",
    "caminho_csv_treino = os.path.join(caminho_base_output, 'df_treino_features.csv')\n",
    "caminho_csv_teste = os.path.join(caminho_base_output, 'df_teste_features.csv')\n",
    "\n",
    "try:\n",
    "    # Salva o DataFrame de treino\n",
    "    df_treino.to_csv(caminho_csv_treino, index=False)\n",
    "    print(f\"\\nDataFrame de TREINO (features) salvo com sucesso em:\")\n",
    "    print(f\"{caminho_csv_treino}\")\n",
    "\n",
    "    # Salva o DataFrame de teste\n",
    "    df_teste.to_csv(caminho_csv_teste, index=False)\n",
    "    print(f\"\\nDataFrame de TESTE (features) salvo com sucesso em:\")\n",
    "    print(f\"{caminho_csv_teste}\")\n",
    "\n",
    "except NameError:\n",
    "    print(\"\\nERRO: Os DataFrames 'df_treino' ou 'df_teste' não foram encontrados.\")\n",
    "    print(\"Certifique-se de que o Bloco 3 foi executado com sucesso antes de salvar.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nOcorreu um erro inesperado ao salvar os arquivos: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
