{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfefd281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando a leitura e segmentação dos arquivos em 'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset'...\n",
      "Dados normais serão divididos em 80% para treino e 20% para teste ANTES da segmentação.\n",
      "\n",
      "--- Processo Concluído! ---\n",
      "Total de segmentos de TREINO (falhas + 80% normais): 3252\n",
      "Total de segmentos de TESTE (20% normais): 115\n",
      "\n",
      "Exemplo de um segmento de TREINO (chave: '1730_B_14_DE_seg_0'):\n",
      "   amplitude      arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0   0.105420  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "1  -0.107370  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "2  -0.163410  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "3   0.118903  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "4   0.184039  1730_B_14_DE12.npz         1730     Esfera         0.014\"   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n",
      "\n",
      "Exemplo de um segmento de TESTE (chave: '1730_Normal_DE_teste_seg_0'):\n",
      "   amplitude   arquivo_origem  rotacao_rpm tipo_falha diametro_falha  \\\n",
      "0  -0.031084  1730_Normal.npz         1730     Normal            N/A   \n",
      "1  -0.072807  1730_Normal.npz         1730     Normal            N/A   \n",
      "2  -0.034004  1730_Normal.npz         1730     Normal            N/A   \n",
      "3   0.069469  1730_Normal.npz         1730     Normal            N/A   \n",
      "4   0.176280  1730_Normal.npz         1730     Normal            N/A   \n",
      "\n",
      "  local_sensor  \n",
      "0    Drive End  \n",
      "1    Drive End  \n",
      "2    Drive End  \n",
      "3    Drive End  \n",
      "4    Drive End  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pprint\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO 1: CONFIGURAÇÃO, CARREGAMENTO, DIVISÃO (80/20) E SEGMENTAÇÃO (CORRIGIDO)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. CONFIGURAÇÕES GERAIS ---\n",
    "caminho_raiz = r'C:\\Users\\vinic\\OneDrive\\Documentos\\Graduação\\TG\\Dataset' # IMPORTANTE: Verifique se este caminho está correto\n",
    "params_drive_end = {'n': 9, 'd': 0.3126, 'D': 1.537, 'phi_graus': 0.0}\n",
    "TAXA_AMOSTRAL = 12000\n",
    "\n",
    "# Dicionários de mapeamento\n",
    "mapa_tipo_falha = {'IR': 'Pista Interna', 'B': 'Esfera', 'OR': 'Pista Externa', 'Normal': 'Normal'}\n",
    "mapa_diametro_falha = {'7': '0.007\"', '14': '0.014\"', '21': '0.021\"'}\n",
    "\n",
    "# --- PARÂMETROS DE SEGMENTAÇÃO ---\n",
    "tamanho_segmento = 4096\n",
    "sobreposicao_percentual = 0.3\n",
    "passo = int(tamanho_segmento * (1 - sobreposicao_percentual))\n",
    "\n",
    "# --- 2. CARREGAMENTO, DIVISÃO E PROCESSAMENTO ---\n",
    "dicionario_treino = {}\n",
    "dicionario_teste = {} # Dicionário para guardar os 20% dos dados normais para teste\n",
    "\n",
    "print(f\"Iniciando a leitura e segmentação dos arquivos em '{caminho_raiz}'...\")\n",
    "print(\"Dados normais serão divididos em 80% para treino e 20% para teste ANTES da segmentação.\")\n",
    "\n",
    "# Função auxiliar para segmentar um sinal e adicionar ao dicionário\n",
    "def segmentar_e_adicionar(sinal, metadados, dicionario_alvo, chave_base):\n",
    "    # Verifica se o sinal é longo o suficiente para pelo menos um segmento\n",
    "    if len(sinal) < tamanho_segmento:\n",
    "        # print(f\"Aviso: Sinal da base '{chave_base}' muito curto ({len(sinal)} amostras) para gerar segmentos. Ignorando.\")\n",
    "        return 0\n",
    "\n",
    "    num_segmentos_criados = 0\n",
    "    for i, inicio in enumerate(range(0, len(sinal) - tamanho_segmento + 1, passo)):\n",
    "        segmento = sinal[inicio : inicio + tamanho_segmento]\n",
    "        df_segmento = pd.DataFrame({'amplitude': segmento})\n",
    "\n",
    "        # Adiciona metadados\n",
    "        df_segmento['arquivo_origem'] = metadados['nome_arquivo']\n",
    "        df_segmento['rotacao_rpm'] = metadados['rpm']\n",
    "        df_segmento['tipo_falha'] = metadados['tipo_falha']\n",
    "        df_segmento['diametro_falha'] = metadados['diametro_falha']\n",
    "        df_segmento['local_sensor'] = 'Drive End'\n",
    "\n",
    "        chave_segmento = f\"{chave_base}_seg_{i}\"\n",
    "        dicionario_alvo[chave_segmento] = df_segmento\n",
    "        num_segmentos_criados += 1\n",
    "    return num_segmentos_criados\n",
    "\n",
    "# Loop principal pelos arquivos\n",
    "for pasta_atual, _, arquivos in os.walk(caminho_raiz):\n",
    "    for nome_arquivo in arquivos:\n",
    "        # Processar apenas arquivos .npz\n",
    "        if nome_arquivo.endswith('.npz'):\n",
    "            caminho_completo = os.path.join(pasta_atual, nome_arquivo)\n",
    "\n",
    "            # Decodificação de metadados\n",
    "            nome_sem_ext = nome_arquivo.replace('.npz', '')\n",
    "            partes = nome_sem_ext.split('_')\n",
    "            rpm_str = partes[0]\n",
    "            is_normal = 'Normal' in nome_arquivo\n",
    "\n",
    "            metadados = {\n",
    "                'nome_arquivo': nome_arquivo,\n",
    "                'rpm': int(rpm_str) if rpm_str.isdigit() else 0,\n",
    "                'tipo_falha': 'Normal' if is_normal else mapa_tipo_falha.get(partes[1].split('@')[0], 'Desconhecido'),\n",
    "                'diametro_falha': 'N/A' if is_normal else mapa_diametro_falha.get(partes[2], 'Desconhecido')\n",
    "            }\n",
    "\n",
    "            try:\n",
    "                dados_npz = np.load(caminho_completo)\n",
    "                sensor_cod = 'DE' # Foco apenas no Drive End, como no seu código original\n",
    "\n",
    "                if sensor_cod in dados_npz.files:\n",
    "                    sinal_completo = dados_npz[sensor_cod].ravel()\n",
    "\n",
    "                    if is_normal:\n",
    "                        # DIVIDE O SINAL NORMAL EM 80/20\n",
    "                        ponto_corte = int(len(sinal_completo) * 0.8)\n",
    "                        sinal_treino = sinal_completo[:ponto_corte]\n",
    "                        sinal_teste = sinal_completo[ponto_corte:]\n",
    "\n",
    "                        chave_base_normal = f\"{nome_sem_ext}_{sensor_cod}\"\n",
    "                        segmentar_e_adicionar(sinal_treino, metadados, dicionario_treino, f\"{chave_base_normal}_treino\")\n",
    "                        segmentar_e_adicionar(sinal_teste, metadados, dicionario_teste, f\"{chave_base_normal}_teste\")\n",
    "\n",
    "                    else:\n",
    "                        # Sinais com falha vão inteiramente para o TREINO\n",
    "                        # Lógica de chave para arquivos de falha (igual ao seu original)\n",
    "                        partes_chave = nome_sem_ext.split('_')\n",
    "                        partes_chave[-1] = partes_chave[-1].rstrip('0123456789')\n",
    "                        chave_base_falha = \"_\".join(partes_chave)\n",
    "                        segmentar_e_adicionar(sinal_completo, metadados, dicionario_treino, chave_base_falha)\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Erro ao processar o arquivo {nome_arquivo}: {e}\")\n",
    "\n",
    "# --- Relatório Final ---\n",
    "print(\"\\n--- Processo Concluído! ---\")\n",
    "print(f\"Total de segmentos de TREINO (falhas + 80% normais): {len(dicionario_treino)}\")\n",
    "print(f\"Total de segmentos de TESTE (20% normais): {len(dicionario_teste)}\")\n",
    "\n",
    "if not dicionario_teste:\n",
    "    print(\"\\nAVISO: O dicionário de teste está vazio. Verifique se os arquivos 'Normal' existem e se os sinais são longos o suficiente (mínimo de ~21000 amostras).\")\n",
    "\n",
    "if dicionario_treino:\n",
    "    chave_exemplo_treino = list(dicionario_treino.keys())[0]\n",
    "    print(f\"\\nExemplo de um segmento de TREINO (chave: '{chave_exemplo_treino}'):\")\n",
    "    print(dicionario_treino[chave_exemplo_treino].head())\n",
    "\n",
    "if dicionario_teste:\n",
    "    chave_exemplo_teste = list(dicionario_teste.keys())[0]\n",
    "    print(f\"\\nExemplo de um segmento de TESTE (chave: '{chave_exemplo_teste}'):\")\n",
    "    print(dicionario_teste[chave_exemplo_teste].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b0aa665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usando 470 segmentos normais de TREINO do Drive End para gerar dados sintéticos.\n",
      "\n",
      "Adicionando os 470 segmentos normais ao conjunto de dados final...\n",
      "\n",
      "\n",
      "--- Geração de Dados Concluída! ---\n",
      "Total de 135830 segmentos (sintéticos + normais) gerados para o Drive End.\n",
      "\n",
      "--- Exemplo do DataFrame Final Gerado ---\n",
      "       tipo_falha_adicionada   rpm  multiplicador_amplitude  \\\n",
      "135825                Normal  1797                      0.0   \n",
      "135826                Normal  1797                      0.0   \n",
      "135827                Normal  1797                      0.0   \n",
      "135828                Normal  1797                      0.0   \n",
      "135829                Normal  1797                      0.0   \n",
      "\n",
      "        fase_adicionada_rad                   base_normal local_sensor  \n",
      "135825                  0.0  1797_Normal_DE_treino_seg_62    Drive End  \n",
      "135826                  0.0  1797_Normal_DE_treino_seg_63    Drive End  \n",
      "135827                  0.0  1797_Normal_DE_treino_seg_64    Drive End  \n",
      "135828                  0.0  1797_Normal_DE_treino_seg_65    Drive End  \n",
      "135829                  0.0  1797_Normal_DE_treino_seg_66    Drive End  \n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# BLOCO DE GERAÇÃO DE DADOS SINTÉTICOS (INCLUINDO SINAIS NORMAIS)\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. FUNÇÃO PARA CÁLCULO DE FREQUÊNCIA TEÓRICA ---\n",
    "def calcular_frequencias_rolamento(n, fr, d, D, phi_graus=0.0):\n",
    "    \"\"\"Calcula as frequências teóricas de falha de um rolamento.\"\"\"\n",
    "    phi_rad = np.deg2rad(phi_graus)\n",
    "    termo_comum = (d / D) * np.cos(phi_rad)\n",
    "    return {\n",
    "        'Pista Externa': (n * fr / 2) * (1 - termo_comum),\n",
    "        'Pista Interna': (n * fr / 2) * (1 + termo_comum),\n",
    "        'Esfera': (D * fr / (2 * d)) * (1 - termo_comum**2)\n",
    "    }\n",
    "\n",
    "# --- 2. PARÂMETROS DE GERAÇÃO (APENAS DRIVE END) ---\n",
    "amplitudes_referencia = {\n",
    "    'Drive End': {'Esfera': 0.0001, 'Pista Interna': 0.001, 'Pista Externa': 0.0001}\n",
    "}\n",
    "multiplicadores = [0.1, 0.25, 0.5, 0.75, 1.0, 1.5, 2.0, 5.0, 10.0, 25.0, 50.0, 100.0]\n",
    "fases_para_adicionar_rad = [\n",
    "    0, np.pi/4, np.pi/2, 3*np.pi/4,\n",
    "    np.pi, 5*np.pi/4, 3*np.pi/2, 7*np.pi/4\n",
    "]\n",
    "\n",
    "# --- 3. IDENTIFICAÇÃO DOS SEGMENTOS NORMAIS DE TREINO ---\n",
    "# A partir de agora, usamos apenas os dados de treino (dicionario_treino)\n",
    "segmentos_normais = {\n",
    "    chave: df for chave, df in dicionario_treino.items()\n",
    "    if df['tipo_falha'].iloc[0] == 'Normal'\n",
    "}\n",
    "print(f\"Usando {len(segmentos_normais)} segmentos normais de TREINO do Drive End para gerar dados sintéticos.\")\n",
    "\n",
    "# --- 4. GERAÇÃO E COMBINAÇÃO DOS SINAIS ---\n",
    "lista_dados_finais = []\n",
    "\n",
    "# Loop para gerar os sinais com falha sintética\n",
    "for chave_normal, df_normal in segmentos_normais.items():\n",
    "    sinal_normal_base = df_normal['amplitude'].values\n",
    "    rpm_atual = df_normal['rotacao_rpm'].iloc[0]\n",
    "    \n",
    "    N_PONTOS = len(sinal_normal_base)\n",
    "    duracao_s = N_PONTOS / TAXA_AMOSTRAL\n",
    "    t = np.linspace(0.0, duracao_s, N_PONTOS, endpoint=False)\n",
    "    \n",
    "    fr_hz = rpm_atual / 60\n",
    "    freqs_teoricas = calcular_frequencias_rolamento(fr=fr_hz, **params_drive_end)\n",
    "    \n",
    "    for tipo_falha_sintetica in ['Pista Externa', 'Pista Interna', 'Esfera']:\n",
    "        freq_teorica = freqs_teoricas[tipo_falha_sintetica]\n",
    "        amp_ref = amplitudes_referencia['Drive End'][tipo_falha_sintetica]\n",
    "            \n",
    "        for mult in multiplicadores:\n",
    "            for fase in fases_para_adicionar_rad:\n",
    "                amplitude_final = amp_ref * mult\n",
    "                sinal_falha_sintetico = amplitude_final * np.sin(2 * np.pi * freq_teorica * t + fase)\n",
    "                sinal_final_combinado = sinal_normal_base + sinal_falha_sintetico\n",
    "                \n",
    "                lista_dados_finais.append({\n",
    "                    'sinal_final': sinal_final_combinado,\n",
    "                    'tipo_falha_adicionada': tipo_falha_sintetica,\n",
    "                    'rpm': rpm_atual,\n",
    "                    'multiplicador_amplitude': mult,\n",
    "                    'fase_adicionada_rad': fase,\n",
    "                    'base_normal': chave_normal,\n",
    "                    'local_sensor': 'Drive End'\n",
    "                })\n",
    "\n",
    "# --- 5. ADIÇÃO DOS SEGMENTOS NORMAIS ORIGINAIS ---\n",
    "print(f\"\\nAdicionando os {len(segmentos_normais)} segmentos normais ao conjunto de dados final...\")\n",
    "for chave_normal, df_normal in segmentos_normais.items():\n",
    "    lista_dados_finais.append({\n",
    "        'sinal_final': df_normal['amplitude'].values,\n",
    "        'tipo_falha_adicionada': 'Normal', # Classe \"Normal\"\n",
    "        'rpm': df_normal['rotacao_rpm'].iloc[0],\n",
    "        'multiplicador_amplitude': 0, # Não aplicável\n",
    "        'fase_adicionada_rad': 0, # Não aplicável\n",
    "        'base_normal': chave_normal,\n",
    "        'local_sensor': 'Drive End'\n",
    "    })\n",
    "\n",
    "# --- 6. DATAFRAME FINAL COM DADOS SINTÉTICOS E NORMAIS ---\n",
    "df_final_completo = pd.DataFrame(lista_dados_finais)\n",
    "\n",
    "print(\"\\n\\n--- Geração de Dados Concluída! ---\")\n",
    "print(f\"Total de {len(df_final_completo)} segmentos (sintéticos + normais) gerados para o Drive End.\")\n",
    "print(\"\\n--- Exemplo do DataFrame Final Gerado ---\")\n",
    "# Mostra as últimas linhas para vermos os exemplos de sinais normais\n",
    "print(df_final_completo.drop(columns=['sinal_final']).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90e3d7d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando extração de atributos de cada SINAL SINTÉTICO (Drive End) ---\n",
      "\n",
      "Extração concluída! Atributos de 169344 sinais sintéticos foram calculados.\n",
      "\n",
      "--- Exemplo do DataFrame final com os atributos extraídos ---\n",
      "  tipo_falha_adicionada   rpm  multiplicador_amplitude  fase_adicionada_rad  \\\n",
      "0         Pista Externa  1730                      0.1             0.000000   \n",
      "1         Pista Externa  1730                      0.1             0.785398   \n",
      "2         Pista Externa  1730                      0.1             1.570796   \n",
      "3         Pista Externa  1730                      0.1             2.356194   \n",
      "4         Pista Externa  1730                      0.1             3.141593   \n",
      "\n",
      "            base_normal   TF2_std   TF3_rms  TF4_fator_forma  \\\n",
      "0  1730_Normal_FE_seg_0  0.073620  0.080450         1.256159   \n",
      "1  1730_Normal_FE_seg_0  0.073620  0.080450         1.256160   \n",
      "2  1730_Normal_FE_seg_0  0.073619  0.080450         1.256159   \n",
      "3  1730_Normal_FE_seg_0  0.073619  0.080449         1.256157   \n",
      "4  1730_Normal_FE_seg_0  0.073618  0.080449         1.256155   \n",
      "\n",
      "   FF2_freq_central  FF3_rms_freq  FF5_assimetria_espectral  \n",
      "0       1213.021191   1743.672804                  1.672554  \n",
      "1       1213.023717   1743.677234                  1.672551  \n",
      "2       1213.030265   1743.684663                  1.672544  \n",
      "3       1213.037001   1743.690741                  1.672538  \n",
      "4       1213.039983   1743.691910                  1.672537  \n",
      "\n",
      "--- Informações do DataFrame de Atributos Sintéticos ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 169344 entries, 0 to 169343\n",
      "Data columns (total 11 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   tipo_falha_adicionada     169344 non-null  object \n",
      " 1   rpm                       169344 non-null  int64  \n",
      " 2   multiplicador_amplitude   169344 non-null  float64\n",
      " 3   fase_adicionada_rad       169344 non-null  float64\n",
      " 4   base_normal               169344 non-null  object \n",
      " 5   TF2_std                   169344 non-null  float64\n",
      " 6   TF3_rms                   169344 non-null  float64\n",
      " 7   TF4_fator_forma           169344 non-null  float64\n",
      " 8   FF2_freq_central          169344 non-null  float64\n",
      " 9   FF3_rms_freq              169344 non-null  float64\n",
      " 10  FF5_assimetria_espectral  169344 non-null  float64\n",
      "dtypes: float64(8), int64(1), object(2)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import skew\n",
    "\n",
    "# =============================================================================\n",
    "# BLOCO DE EXTRAÇÃO DE ATRIBUTOS DOS SINAIS SINTÉTICOS GERADOS\n",
    "# =============================================================================\n",
    "\n",
    "# --- 1. FUNÇÕES PARA CÁLCULO DOS ATRIBUTOS ---\n",
    "\n",
    "# --- DOMÍNIO DO TEMPO ---\n",
    "def calcular_tf2_std(sinal):\n",
    "    \"\"\"Calcula o Desvio Padrão (TF2).\"\"\"\n",
    "    return np.std(sinal)\n",
    "\n",
    "def calcular_tf3_rms(sinal):\n",
    "    \"\"\"Calcula o valor RMS (TF3).\"\"\"\n",
    "    return np.sqrt(np.mean(sinal**2))\n",
    "\n",
    "def calcular_tf4_fator_forma(sinal):\n",
    "    \"\"\"Calcula o Fator de Forma (TF4).\"\"\"\n",
    "    rms = calcular_tf3_rms(sinal)\n",
    "    media_abs = np.mean(np.abs(sinal))\n",
    "    return rms / media_abs if media_abs != 0 else 0\n",
    "\n",
    "# --- DOMÍNIO DA FREQUÊNCIA ---\n",
    "def calcular_features_frequencia(sinal, taxa_amostral):\n",
    "    \"\"\"Calcula FF2, FF3 e FF5 de uma só vez.\"\"\"\n",
    "    N = len(sinal)\n",
    "    if N == 0: return None, None, None\n",
    "\n",
    "    # Aplica a FFT e obtém o espectro de amplitude\n",
    "    espectro = np.abs(np.fft.fft(sinal)[0:N//2])\n",
    "    freqs = np.fft.fftfreq(N, 1 / taxa_amostral)[:N//2]\n",
    "    \n",
    "    soma_espectro = np.sum(espectro)\n",
    "    if soma_espectro == 0: return 0, 0, 0\n",
    "\n",
    "    # FF2: Frequência Central\n",
    "    ff2_freq_central = np.sum(freqs * espectro) / soma_espectro\n",
    "    \n",
    "    # FF3: RMS da Frequência\n",
    "    ff3_rms_freq = np.sqrt(np.sum((freqs**2) * espectro) / soma_espectro)\n",
    "    \n",
    "    # FF4: Desvio Padrão da Frequência (necessário para FF5)\n",
    "    ff4_std_freq = np.sqrt(np.sum(((freqs - ff2_freq_central)**2) * espectro) / soma_espectro)\n",
    "    \n",
    "    # FF5: Assimetria Espectral\n",
    "    numerador_ff5 = np.sum(((freqs - ff2_freq_central)**3) * espectro) / soma_espectro\n",
    "    ff5_assimetria = numerador_ff5 / (ff4_std_freq**3) if ff4_std_freq != 0 else 0\n",
    "        \n",
    "    return ff2_freq_central, ff3_rms_freq, ff5_assimetria\n",
    "\n",
    "\n",
    "# --- 2. PROCESSAMENTO E EXTRAÇÃO DE FEATURES ---\n",
    "\n",
    "print(\"--- Iniciando extração de atributos de cada SINAL SINTÉTICO (Drive End) ---\")\n",
    "lista_de_features = []\n",
    "\n",
    "# Itera sobre o DataFrame com os sinais sintéticos do Drive End\n",
    "# O método .itertuples() é mais rápido que iterrows()\n",
    "for linha in df_final_de.itertuples():\n",
    "    sinal_sintetico = linha.sinal_final\n",
    "    \n",
    "    # Calcula os atributos\n",
    "    tf2 = calcular_tf2_std(sinal_sintetico)\n",
    "    tf3 = calcular_tf3_rms(sinal_sintetico)\n",
    "    tf4 = calcular_tf4_fator_forma(sinal_sintetico)\n",
    "    ff2, ff3, ff5 = calcular_features_frequencia(sinal_sintetico, TAXA_AMOSTRAL)\n",
    "    \n",
    "    # Armazena os resultados junto com os metadados\n",
    "    lista_de_features.append({\n",
    "        'tipo_falha_adicionada': linha.tipo_falha_adicionada,\n",
    "        'rpm': linha.rpm,\n",
    "        'multiplicador_amplitude': linha.multiplicador_amplitude,\n",
    "        'fase_adicionada_rad': linha.fase_adicionada_rad,\n",
    "        'base_normal': linha.base_normal,\n",
    "        'TF2_std': tf2,\n",
    "        'TF3_rms': tf3,\n",
    "        'TF4_fator_forma': tf4,\n",
    "        'FF2_freq_central': ff2,\n",
    "        'FF3_rms_freq': ff3,\n",
    "        'FF5_assimetria_espectral': ff5\n",
    "    })\n",
    "\n",
    "# --- 3. CRIAÇÃO DO DATAFRAME FINAL DE ATRIBUTOS ---\n",
    "df_features_sinteticas = pd.DataFrame(lista_de_features)\n",
    "\n",
    "print(f\"\\nExtração concluída! Atributos de {len(df_features_sinteticas)} sinais sintéticos foram calculados.\")\n",
    "print(\"\\n--- Exemplo do DataFrame final com os atributos extraídos ---\")\n",
    "print(df_features_sinteticas.head())\n",
    "\n",
    "# Mostra informações sobre o DataFrame final\n",
    "print(\"\\n--- Informações do DataFrame de Atributos Sintéticos ---\")\n",
    "df_features_sinteticas.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
